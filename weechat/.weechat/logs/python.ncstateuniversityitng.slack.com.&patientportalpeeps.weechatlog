2018-03-16 14:45:27		getting channel history...
2018-02-07 19:36:37	Sagar	records were in xml format so you have to tell which part of it related to you 
2018-02-07 19:37:08	Sagar	I am trying to figure out what is the content of records 
2018-02-07 19:38:05	Sagar	Ahh got it 
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-16 15:00:22		getting channel history...
2018-02-07 19:36:37	Sagar	records were in xml format so you have to tell which part of it related to you 
2018-02-07 19:37:08	Sagar	I am trying to figure out what is the content of records 
2018-02-07 19:38:05	Sagar	Ahh got it 
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-19 16:42:52		getting channel history...
2018-02-07 19:36:37	Sagar	records were in xml format so you have to tell which part of it related to you 
2018-02-07 19:37:08	Sagar	I am trying to figure out what is the content of records 
2018-02-07 19:38:05	Sagar	Ahh got it 
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-28 10:19:27		getting channel history...
2018-02-07 19:36:37	Sagar	records were in xml format so you have to tell which part of it related to you 
2018-02-07 19:37:08	Sagar	I am trying to figure out what is the content of records 
2018-02-07 19:38:05	Sagar	Ahh got it 
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-28 10:21:49	jesse	Hey did anyone kill a program on pubmed-jesse within the past 12 hours?  
2018-04-05 14:12:49		getting channel history...
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-28 10:21:49	jesse	Hey did anyone kill a program on pubmed-jesse within the past 12 hours?  
2018-03-28 13:05:54	Arun	Nope, not me! 
2018-03-28 16:38:56	Sagar	No 
2018-04-19 16:52:10		getting channel history...
2018-02-07 19:38:47	Sagar	It has 'PubmedArticle' and 'PubmedBookArticle' so we just need pubmed article 
2018-02-07 19:45:29	Janne	Yeah I noticed that too, the data structure of all this is kinda overwhelming lol 
2018-02-07 19:45:44	Janne	I wish they had documentation on these returned data structures 
2018-02-07 19:49:44	Sagar	Yeah we have everything related to articles lol 
2018-02-07 19:49:52	Sagar	There is one better 
2018-02-07 19:49:57	Sagar	Let me send you the link 
2018-02-07 19:50:06	Janne	Perf! 
2018-02-07 19:50:20	Sagar	https://www.ncbi.nlm.nih.gov/books/NBK25499/
2018-02-07 19:50:20		The E-utilities In-Depth: Parameters, Syntax and More
2018-02-07 19:50:20		This chapter serves as a reference for all supported parameters for the E-utilities, along with accepted values and usage guidelines. This information is provided for each E-utility in sections below, and parameters and/or values specific to particular databases are discussed within each section. Most E-utilities have a set of parameters that are required for any call, in addition to several additional optional parameters that extend the tool's functionality. These two sets of parameters are discussed separately in each section. 
2018-02-07 19:51:01	Janne	Wait this is the same site I'm using lol 
2018-02-07 19:51:19	Sagar	Okay lol 
2018-02-07 19:51:36	Sagar	Another one I'm using for reference is this: 
2018-02-07 19:51:37	Sagar	http://biopython.org/DIST/docs/api/Bio.Entrez-module.html 
2018-02-07 19:56:09	Janne	Lol we are sharing some sort of mindset rn, I have that tab also open :slightly_smiling_face: 
2018-02-07 19:56:35	Janne	But to be honest there's not that much documentation about entrez other than  few sites lol 
2018-02-07 19:59:16	Sagar	Yeah true lol 
2018-02-07 20:00:18	Sagar	There was one article on entrez, it was great. I followed the steps that person said to create the crawler [:heart_eyes:1] 
2018-02-07 20:02:45	Sagar	And what email id you used? 
2018-02-07 20:02:57	Sagar	I saw your message later but forget to asked 
2018-02-07 20:03:16	Janne	Oh its all good, I made an acct with pubmed so I just used that email 
2018-02-07 20:03:32	Sagar	Oh 
2018-02-07 20:03:43	Sagar	I use a hack lol 
2018-02-07 20:04:24	Sagar	And it worked 
2018-02-07 20:04:30	Janne	Niceeee 
2018-02-07 20:04:36	jesse	:slightly_smiling_face: 
2018-02-07 20:04:42	Sagar	mailto:email@email.com (email@email.com) lol 
2018-02-07 20:04:57	Janne	I'm hirting lol 
2018-02-07 20:05:03	Janne	maybe the api doesn't need an email 
2018-02-07 20:05:40	Sagar	Sorry, didn't mean to. I saw your message after you created your account 
2018-02-07 20:05:54	jesse	im trying to run agens graph, but I cant remove to reinstall because postgresql depends on it... and I can't remove postgresql because agensgraph depends on it... 
2018-02-07 20:06:08	Janne	It's all good! [:slightly_smiling_face:1] 
2018-02-07 20:06:26	Janne	Oh nooo 
2018-02-07 20:06:58	Sagar	Yes I was doing the agensgraph thing 
2018-02-07 20:07:02	Janne	Idk if removing both could work :disappointed: 
2018-02-07 20:07:14	jesse	did you get it to work sagar? 
2018-02-07 20:07:53	jesse	if ya did, I'll go to messing with the django issues. 
2018-02-07 20:08:15	Sagar	Agensgraph is based on postgres. I fooled the steps and it is working I think but I have no idea how to test it 
2018-02-07 20:08:28	Sagar	I then installed the gephi 
2018-02-07 20:08:50	Sagar	And I have successfully installed the agensgraph plugin into it [:heart_eyes:1] 
2018-02-07 20:09:18	Sagar	I need test cases to run now 
2018-02-07 20:09:48	Sagar	I think postgres->agensgraph->gephi->UI is all linked now 
2018-02-07 20:12:23	Sagar	Janne you meant removing email ids? 
2018-02-07 20:12:37	Janne	Wait what? 
2018-02-07 20:12:41	Janne	When did I say that? 
2018-02-07 20:12:43	Janne	lol 
2018-02-07 20:13:01	Sagar	"Idk if removing both could work :disappointed:" 
2018-02-07 20:13:18	Janne	Oh I meant postgres and agensgraph for jesse 
2018-02-07 20:14:13	Sagar	Oh okay lol 
2018-02-07 20:15:02	jesse	Yeah I found a way to remove both by installing a library that would purposefully conflict with agens lol... dunno if I'll try to reinstall since sagar got it running. 
2018-02-07 20:15:11	Sagar	Jesse I think you can remove agensgraph because it depends on postgres but postgres does not depends on that 
2018-02-07 20:15:31	jesse	it did on my system... it was weird, but i fixed it. 
2018-02-07 20:15:54	Sagar	I need test cases to make sure if it running, until then I am not sure myself 
2018-02-07 20:16:22	Sagar	Because I followed the steps mentioned on their repo and it all worked 
2018-02-07 20:16:42	Janne	So if you guys are going to tackle the agensgraph thing I can mainly focus on the drug companies. I wouldn't want us to be doing duplicate work 
2018-02-07 20:17:38	Sagar	What will be your task with drug companies, because I don't know what we are supposed to do with that without Yurika 
2018-02-07 20:20:13	Sagar	I have found a way to make our results from crawler in JSON format instead of text 
2018-02-07 20:24:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F955V7PB3/todo.png (todo.png) and commented: Am I missing anything? 
2018-02-07 20:43:08	Sagar	Some issues we have to come up with tomorrow:
2018-02-07 20:43:08		1. How we are supposed to use our pubmed crawler as name is not a good idea (I tried searching for one name that is in the specialist table but didn't got any results. One thing I found that 'Doolittle, Robert, Prince' is mentioned as 'Doolittle, Robert P')
2018-02-07 20:43:08		2. Is there a use in including pharmacies and nursing homes data to relate specialist with that? As I have already linked specialists to hospitals.
2018-02-07 20:43:08		3. How to perform agensgraph testing?
2018-02-07 20:43:08		4. Clarification on Django issues, because I was going through them but I was not sure what they want in some (like ID integer issue).
2018-02-07 20:43:08		Any other issues, that we have now? 
2018-02-07 20:46:30	jesse	1. if we have a name like that, we can use N-gram analysis to determine that those two names are the same. (it would compare the strings by trying "doolittle robert prince", "robert prince doolittle", etc... we would just strip out the commas in the file.)  We would need all of the documents downloaded first though, so we couldn't use a crawler.  (edited)
2018-02-07 20:47:19	jesse	3. I'm pretty sure he wants us to figure out how to do that... Our task was to learn about agensgraph and how to incorporate it within our data. 
2018-02-07 20:49:42	jesse	5. Also, some of their commits broke django. dunno what thats all about 
2018-02-07 20:51:32	jesse	I kinda understand the django issues cuz meaghans been talking with me about that. I still need some clarification tho. 
2018-02-07 20:58:38	Sagar	1. Yes you are right, we need everything to perform that or we can also crawl for all n gram possibilities
2018-02-07 20:58:38		5. I didn't knew about that because I am not able to log in into django somehow 
2018-02-07 21:00:00	jesse	like you can't login at all? or just to view the dbs? 
2018-02-07 21:01:16	Sagar	Yes I can't login at all after running the server when login screen appears in browser 
2018-02-07 21:04:58	jesse	did you follow all the instructions in the github readmes? 
2018-02-07 21:07:34	Sagar	Yes I did 
2018-02-07 21:07:59	Sagar	I also tried running without environment 
2018-02-07 21:08:15	jesse	i don't remember where I set my username and pw. but it isn't what meaghan has. my username is "jesse" 
2018-02-07 21:08:16	Sagar	And made the changes to settings.py 
2018-02-07 21:08:58	Sagar	I used the same credentials as I used to connect to ncbi database 
2018-02-07 21:09:32	jesse	also theres a diseases.txt in the project that's more extensive than the one that I was using. you guys may want to check it out. its in the rarediseases django project 
2018-02-07 21:10:44	jesse	yeah there was another username/pw that wasnt just in the settings.py... i just cant find it.. it may have just been a terminal command or something in the setup instructions 
2018-02-07 21:11:55	Sagar	there was one in settings.ex.py also 
2018-02-07 21:12:03	Sagar	I made the changes to that one also 
2018-02-07 21:12:15	jesse	thats an example of settings.py... don't push that change 
2018-02-07 21:12:34	Sagar	python manage.py migrate, I think that was the command line you are talking about 
2018-02-07 21:12:49	Sagar	Okay I will revert it back 
2018-02-07 21:13:10	jesse	dont revert settings.py... just settings.ex.py 
2018-02-07 21:13:22	jesse	and that may be it.. thats the username and pw you are supposed to put in 
2018-02-07 21:13:42	Sagar	Yes settings.ex.py I will revert that 
2018-02-08 14:01:47	Janne	@everyone I made a python script that grabs the data from the licensed facilities from this site https://www2.ncdhhs.gov/dhsr/reports.htm
2018-02-08 14:01:47		NC DHSR: Licensed Facilities
2018-02-08 14:01:47		WWW Computer Data for North Carolina Division of Health Service Regulation [:heart_eyes:1] 
2018-02-08 14:02:25	jesse	Awesome! 
2018-02-08 14:02:25	Janne	code and files are in our pubmed_scripts repo and I made a separate folder called nc_licensed_facilities 
2018-02-08 14:03:18	jesse	you guys can remove the scripts that I put in if you have different ones.. and you can remove the txt files if you'd like,, since i don't think you guys are using them 
2018-02-08 14:07:39	Janne	OMG YALL 
2018-02-08 14:07:59	jesse	? 
2018-02-08 14:08:02	Janne	I didn't know that if you upload  csv into git it will automatically create a table when viewin the doc 
2018-02-08 14:08:24	Janne	@Janne uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQDGG2C/F978J02JK/screen_shot_2018-02-08_at_2.08.06_pm.png (Screen Shot 2018-02-08 at 2.08.06 PM.png) 
2018-02-08 14:08:33	Janne	Lol the things that make me happy in life 
2018-02-08 14:08:46	jesse	That is actually really cool 
2018-02-08 14:12:22	Janne	Righttttt 
2018-02-08 14:12:29	Janne	but it doesn't do it if the file is too big 
2018-02-08 14:19:00	jesse	yeah github has a wierd thing about having a constant width for content.. I ran into issues with that in SE, cuz they wanted big tables of all of our test case scenarios 
2018-02-08 14:19:09	jesse	in markdown 
2018-02-08 14:26:13	jesse	Janne, didn't we have PLM yesterday? 
2018-02-08 14:26:51	jesse	I coulda sworn we did, and yet today is thursday... 
2018-02-08 14:28:08	Janne	Lol yeah no we have it two days ago, but i totally feel you 
2018-02-08 14:28:17	Janne	this week has gone by INCREDIBLE FAst 
2018-02-08 14:30:45	jesse	yeah it has. i've hardly been able to keep up :disappointed: 
2018-02-08 18:19:36	jesse	hey guys, just to let you know, there is a diseases.txt file in rarediseases on github... its a better list than I created so please use that one 
2018-02-11 22:14:59	jesse	I changed the name of our pubmed scripts repo to raredx_scripts... this seems more fitting cuz I was thinking of including more things that werent just pubmed related. 
2018-02-11 22:17:17	jesse	can i remove the pubmed stuff that I created that no one ended up using? 
2018-02-12 16:35:43	jesse	I'm gonna be working on raredx stuff for the next few hours. let me know if you guys are too so I can message ya. 
2018-02-12 18:31:29	jesse	I'm having some trouble with the general contractor data that I'm scraping. I'm having trouble with the lack of consistency with this websites info. This leads to some unusual entries in the csv that I'm generating. Can someone take a look? 
2018-02-12 18:35:42	jesse	i might have a way to get around this. 
2018-02-12 18:36:17	Janne	what's the link to the site? 
2018-02-12 18:37:02	jesse	it would look like this: https://nclbgc.org/search/qualifierDetails?key=68a127f30e&licenseNumber=73064  (edited)
2018-02-12 18:40:05	jesse	the issue is sometimes the address would make 2 or 3 rows rather than staying within its single row. 
2018-02-12 18:40:18	jesse	and how I'm getting the data is by using beautiful soup to fetch the rows 
2018-02-12 18:40:48	jesse	I think I might have a way by using pandas and a string builder. 
2018-02-12 19:13:33	jesse	I resolved my issue. its just gonna look weird in the CSV when someone has more than one phone number or address. 
2018-02-12 19:14:20	jesse	yay for webcrawling 33,000 more websites again 
2018-02-12 19:41:47	jesse	Hey Janne, I noticed all of the CSV files you pushed in the scripts repo. Would you like me to make a database out of it? 
2018-02-12 19:49:09	jesse	I've got another question.. In my notes from last meeting, I wrote down that we need to categorize the diseases (using nord). Was this something we were supposed to do? or was that a task for meaghan/mike/ other ppl 
2018-02-12 20:30:56	Sagar	Dr. Kowolenko was fetching the nord data and once it's done, I think we were supposed to categorize it. We just have to wait for him to finish that and see if categorization is done or not by him 
2018-02-13 13:20:20	jesse	Have either of you guys spoken with Arun since the meeting? 
2018-02-13 13:21:01	jesse	BTW I got a csv of the general contractors as well as the companies that those contractors come from. 
2018-02-13 14:32:18	Sagar	I have not spoken with him. 
2018-02-13 14:32:18		That's great! We are getting in good shape in terms of refining our database. 
2018-02-13 17:23:16	Arun	@Arun has joined the group 
2018-02-13 17:23:43	jesse	Just added Arun to this chat 
2018-02-13 17:23:56	Arun	Hey guys! :slightly_smiling_face: 
2018-02-13 17:30:40	jesse	hello. To Sagar/Janne, I would like you guys to push your scripts for the pubmed data/specialists/raredx to the git repo (for linking specialist to raredx). I would like Arun to continue working on those scripts since both of you (sagar/janne) have other tasks that need to be done. 
2018-02-13 17:58:59	Arun	Yeah, I can work on it once they push their scripts! 
2018-02-14 21:48:47	jesse	I noticed nobody has pushed their pubmed web crawling scripts... Be real with me you guys, do these scripts exist?  
2018-02-14 21:48:47		I had a ginormous text file that I was trying to process a lil over a week ago, that i held off on because you guys started making something better and involving magical python libraries.  
2018-02-14 23:01:41	Sagar	Hey Guys, sorry for the delay in response, I didn't got any notification for yesterdays messages. 
2018-02-14 23:01:41		Hi Arun, welcome to our team, I guess the first impression wasn't good. 
2018-02-14 23:01:41		Jesse, I understand how you must be feeling now dude. I'll go ahead and push the pubmed script. 
2018-02-14 23:02:13	Sagar	Arun, if you need any help with initial understanding let me know [:+1:1 :slightly_smiling_face:1] 
2018-02-14 23:03:38	jesse	awesome! thanks Sagar!! 
2018-02-14 23:04:23	Sagar	Again, sorry guys for delay 
2018-02-14 23:06:19	jesse	you're good.  
2018-02-14 23:21:04	Sagar	Okay, so the script is over the GitHub server and currently I have found a way to print the data retrieved in the form of JSon structure, so that everyone has better understanding of how the data is stored in PubMed and what Headers are used by PubMed to store the articles. We can now also save the whole PubMed data in the form of JSon file if we want :smile: [:heart_eyes:1]  (edited)
2018-02-14 23:22:25	jesse	...i wonder how many gigabytes of pure JSON that would be lol 
2018-02-14 23:22:41	Sagar	Yeah true lol 
2018-02-14 23:23:16	Sagar	I just need to know the max number articles the PubMed has and put that number and save that JSon print to a file to know that lol 
2018-02-15 10:15:03	Arun	I will first start with taking a look at the repo and understand whats been on. If I am not clear on something, i'll let you know guys, thank you :slightly_smiling_face: [:smile:1] 
2018-02-19 10:40:26	jesse	I uploaded the csv of the pubmed articles to the google drive in the pubmed folder.  Whenever you guys are opening it up in some office application, be sure to only separate entries by comma. otherwise, the data may overflow into other cells. [:+1:2] 
2018-02-20 10:36:55	jesse	Hey guys, I'm planning on putting all of the scripts inside the django rarediseases repository. Are there any scripts you guys are currently working on that needs to be pushed? 
2018-02-20 11:00:57	jesse	I moved everything over to the rarediseases repo. I would appreciate it if you guys stopped using the raredx_scripts repo so that we do not have to move anything over. One more thing, they do not want any of the data generated to be pushed to the rarediseases repo so please be aware of your commits. 
2018-02-20 11:02:22	jesse	The data generated can remain in the current raredx_scripts repo and amongst our google drive. If they are going to be turned into tables, Meaghan wants them on power6a. 
2018-02-20 12:04:33	Arun	I am working on a script that relates doctors and rarediseases, based on the articles! I will push them into the rarediseases repo once I am done  
2018-02-20 12:57:25	jesse	awesome! 
2018-02-20 12:59:36	jesse	also to Sagar and maybe Janne, on  the wiki for the rarediseases repo, we need to go through the schema for each table/csv we made and list out what the columns mean for each table. I did as much as I could, but the remaining tables still have quite a lot that I'm not sure about. If you're unsure about any field, you can mark it as "Unsure." as I have many times already. [:+1:1] 
2018-02-22 15:41:04	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9DCWSG3E/notes7_todo_md.md (notes7_todo.md) and commented: Hey guys, I put together  a text file of things we need to do/ notes for this week. Let me know if I have forgotten anything. 
2018-02-22 15:46:12	jesse	I don't really know what Sagar/Arun is working on this week.. So I guess just let us know in this chat some time. 
2018-02-22 18:26:45	Sagar	Tasks that I had to do this week:
2018-02-22 18:26:45		Resolve zip issue - Done
2018-02-22 18:26:45		Clean data - Remove Pharmacies
2018-02-22 18:26:45		I guess I can help you out Jesse with the task 1 then as I will not have anything after that. Also just to make sure, is the Task 1 you mentioned was the one Dr. Kowolenko discussed before the meeting and then he explained it on board later on  (edited)
2018-02-22 18:41:05	jesse	yep 
2018-02-22 18:42:38	jesse	and i expect that to be a decent amount of work so I would appreciate the help.
2018-02-22 18:42:38		btw, Thomas' repo is http://github.com/tdortiz (github.com/tdortiz) and look in the CSC495 repo for the hospital rating system project [:+1:1] 
2018-02-24 17:02:17	jesse	hey guys, i'm noticing a problem with the pubmed data that we have. There is a lot of duplicate entries. If the same article comes up in two different searches for a particular rare disease, that article will list twice. I'm not sure how I want to fix this yet. 
2018-02-24 17:13:06	jesse	I'm writing a script now to fix this. 
2018-02-24 19:32:53	jesse	once I filtered out all of the duplicates, I realized there were a ton of empty entries or partially filled entries... so I gotta recreate the pubmed table. 
2018-02-25 11:08:08	jesse	I removed the duplicates and appended the queried rare disease and made a csv for it. the partially filled entries are actually a result of those fields not existing rather than those fields being lost in my scripts. 
2018-02-25 11:11:13	jesse	I would like to meet up with someone about this stuff tomorrow if anyone is free. I can also help out with the things you guys are working on. [:+1:1] 
2018-02-25 18:27:25	Arun	I can meet you tomorrow 
2018-02-25 18:29:11	jesse	would you be able to meet some time after 5?  
2018-02-25 18:40:28	Arun	Yeah sure, after 5 sounds good! I?ll confirm the time by tomorrow noon? 
2018-02-25 18:41:04	jesse	sure 
2018-02-26 12:42:08	jesse	Would you guys be available to meet at 6pm? I can meet earlier but I'd prefer to eat dinner before I meet. 
2018-02-26 14:29:39	Janne	I'm meeting with my senior design team at 5:30 
2018-02-26 14:29:59	Janne	I'm about to head over to the library soon, so I can meet earlier if you want 
2018-02-26 14:33:05	jesse	I'm gonna be in class up until 4:15.  i could probably get to hunt by 4:30 if you could do that. Arun told me he couldn't meet today. 
2018-02-26 14:35:07	jesse	often times my class gets out early too. 
2018-03-01 14:01:47	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9J0QU0G6/notes8_todo.md (notes8_todo.md) and commented: This weeks notes/todo. 
2018-03-01 14:03:09	jesse	Let us know if you need help with the drug company stuff Janne. And maybe push your script too so that I can have a look If I get bored :slightly_smiling_face: 
2018-03-01 14:08:44	jesse	I also forgot to add that we need to be able to incorporate that physician rare disease stuff with our front end as well. 
2018-03-02 09:33:45	jesse	Let me know if you guys are doing rare disease stuff today. I plan on working on it till around 2 or 3 ish.. 
2018-03-02 14:13:53	jesse	Hey guys, I did a decent amount of stuff since my last message. I modified my pubmed script (again (-_- )  ) and re-ran it since it wasn't listing authors outside of NC... While thats running, I got that CSV and schema for the new specialists and handed that over to meaghan. I've also looked at the mesh terms and learned a few things related to the data we were collecting and what data we need to be collecting.
2018-03-02 14:13:53		Turns out the data we are collecting is a small subset of all the data that is included by searching through the MeSH terms. What this means, is that our data on what articles were about which diseases is correct so long as the mesh terms are correct. We will need to look more into what specifically those mesh terms are so that we can get the entire set of documents relating to a particular rare disease rather than the small subset. I also gathered a list of 150 medical schools in the United States. I'm  currently working on removing the 'meaningless' words such as 'medical school'. I think I had asked you to work on something like this Arun, so let me know if you have made anything that could help compare medical school names... I also tried to gather the names of every university in the country. We will need to decide which is better to use. Do we just want pubmed articles in the few recognized medical schools? or is North Carolina State University School of Veterinary Medicine sufficient? 
2018-03-02 14:24:46	jesse	I got 990 universities. 
2018-03-02 14:38:59	jesse	We may want to stick with our data set for hospitals since ours includes around 40 more hospitals that are open.... although that data set isn't nation-wide... its something to consider 
2018-03-03 08:52:06	jesse	all of the pubmed data is gathered for each rare disease. it's roughly 15 gigs so don't expect me moving it to the Google drive. [:open_mouth:1] 
2018-03-03 08:57:33	jesse	I'll try to work something out so that you guys can get the data if you need it 
2018-03-05 20:29:41	jesse	Quick update. I was able to remove the duplicates. The big file sizes and pandas was a HUGE issue today but I found a way around those problems. Once I get that stuff uploaded and get meaghan to put it in the db, I'll be working on getting the medical schools and last names to match up. Once that's done, we can make the django stuff and be good to go for the week.. 
2018-03-05 20:30:16	jesse	Maybe we can look into making our data smarter with the mesh terms. 
2018-03-06 02:48:05	Arun	Yeahh, sounds like a plan! And great that you were able to fix the issues with duplicates. :-) 
2018-03-06 14:21:38	jesse	I ended up having to regenerate the pubmed data, so I havent been on the med school thing until now. is anyone else workin on this stuff right now? 
2018-03-06 14:52:08	Arun	I'm afraid not. 
2018-03-06 14:53:01	jesse	thats alright. 
2018-03-11 21:10:37	jesse	Hey guys, I'd like to meet up with you guys tomorrow either before 11AM or after 5PM to discuss our next steps as far as the pubmed connections go. Let me know if you guys are available. 
2018-03-12 13:54:02	Arun	Hey, sure! I can meet you today around 6pm if you guys haven?t met already  
2018-03-12 13:54:30	Janne	I can also meet today! 
2018-03-12 13:55:48	jesse	awesome! and I have not met up with anyone. Wanna meet at Hunt? Id say oscar lab, but I dont think the building would be open passed 6. 
2018-03-12 15:29:39	jesse	i reserved  hunt  2327 for an hour. 6 to 7 
2018-03-12 15:52:19	Sagar	I don't think I will make it, I have to catch up with something else. I'll try but if not I'll be available here in Slack if you need me. Sorry about that. 
2018-03-12 17:44:01	jesse	I'm here whenever you guys are ready 
2018-03-12 17:44:13	jesse	and thats alright Sagar 
2018-03-12 17:44:15	Janne	I'm still meeting with another group, I'll head over when we are done :slightly_smiling_face: 
2018-03-12 17:44:25	jesse	ok 
2018-03-12 17:46:56	Arun	I am just about to start and its snowing outside!:face_with_rolling_eyes: How did you guys get to library? Any idea if the buses are still running? 
2018-03-12 17:49:55	jesse	I walked. And I'm sure the buses are still running. 
2018-03-12 17:50:19	Arun	I think i'm running late, but I'll be there. 
2018-03-12 17:51:38	jesse	cool! 
2018-03-12 18:12:10	Sagar	Will it be okay if I come there now 
2018-03-12 18:24:53	jesse	Absolutely! 
2018-03-28 10:21:49	jesse	Hey did anyone kill a program on pubmed-jesse within the past 12 hours?  
2018-03-28 13:05:54	Arun	Nope, not me! 
2018-03-28 16:38:56	Sagar	No 

2018-03-16 14:45:27		getting channel history...
2018-03-06 11:02:08	jesse	Hey Michael, when I find a link between the last name and the medical school name between the pubmed authors and the specialists, where should I put the new column (in specialists?)? and should that new column be the pmid's of the articles that they published? or would you just want the associated rare disease? 
2018-03-06 11:05:10	jesse	I'm thinking the PMID's of the articles would be best. then we can query on the PMID's associated with a rare disease, and then query the specialists who worked on a particular PMID. 
2018-03-06 11:05:26	jesse	Do you have thoughts? 
2018-03-06 11:06:54	msbrown3	yes. I have thoughts 
2018-03-06 11:07:17	jesse	:slightly_smiling_face: 
2018-03-06 11:08:03	msbrown3	do you have a unique id for each specialist? 
2018-03-06 11:09:00	jesse	I'll check but I'm pretty certain that is a yes. 
2018-03-06 11:10:17	msbrown3	ok. I think the best way to store it is this: 
2018-03-06 11:10:24	jesse	yup 
2018-03-06 11:10:37	jesse	^ as in we do have a unique id for each specialist 
2018-03-06 11:10:41	msbrown3	Make a table with (specialist id, disease id, pubmed id) 
2018-03-06 11:11:45	msbrown3	for each of the IDs, either use a foreign key to the table, or use a unique id that won't change (like use id_orpha instead of id for disease) 
2018-03-06 11:14:21	jesse	sounds good except for the disease id part. Our data only has the disease name, which was obtained from the diseases.txt file that we weren't supposed to be using anymore. I never went back to change that part since it would take 24ish hours to generate the pubmed articles. Also, some of the articles would have multiple rare diseases associated with it. Would you be ok if that column was a list of the disease id's or disease names? 
2018-03-06 11:17:29	jesse	:cry: 
2018-03-06 11:18:46	msbrown3	the names are actually different in there. can you regenerate the pubmed data so you can get the disease IDs? even though it will take a while we need the names to match 
2018-03-06 11:19:13	msbrown3	just curious, what id are you going to use for specialists? 
2018-03-06 11:19:53	jesse	NPI I would assume. 
2018-03-06 11:21:22	msbrown3	ok, NPI sounds good 
2018-03-06 11:24:01	jesse	And as for regenerating the pubmed data, should we query on the disease name like we did before? or try to query on the mesh terms? Mesh terms would be a  larger set of data. 
2018-03-06 11:25:29	jesse	but we also don't have all of the mesh terms 
2018-03-06 11:26:11	msbrown3	yeah. If it's not hard, you can MeSH if we have it and search disease name as a backup 
2018-03-06 11:26:23	msbrown3	but for now it's not a big deal if you just want to do disease name 
2018-03-06 11:27:56	jesse	I think I'll go with the disease name... I'm not sure how hard that stuff is going to be, and I'm a lil worried about ram for making the files haha. 
2018-03-06 11:28:21	msbrown3	haha. ok. we can always make those refinements later 
2018-03-06 11:28:50	jesse	sounds good. 
2018-03-06 11:29:35	jesse	rarediseases_disease is where I should get the data from right? 
2018-03-06 11:29:46	msbrown3	yes 
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-16 22:32:08		getting channel history...
2018-03-06 11:02:08	jesse	Hey Michael, when I find a link between the last name and the medical school name between the pubmed authors and the specialists, where should I put the new column (in specialists?)? and should that new column be the pmid's of the articles that they published? or would you just want the associated rare disease? 
2018-03-06 11:05:10	jesse	I'm thinking the PMID's of the articles would be best. then we can query on the PMID's associated with a rare disease, and then query the specialists who worked on a particular PMID. 
2018-03-06 11:05:26	jesse	Do you have thoughts? 
2018-03-06 11:06:54	msbrown3	yes. I have thoughts 
2018-03-06 11:07:17	jesse	:slightly_smiling_face: 
2018-03-06 11:08:03	msbrown3	do you have a unique id for each specialist? 
2018-03-06 11:09:00	jesse	I'll check but I'm pretty certain that is a yes. 
2018-03-06 11:10:17	msbrown3	ok. I think the best way to store it is this: 
2018-03-06 11:10:24	jesse	yup 
2018-03-06 11:10:37	jesse	^ as in we do have a unique id for each specialist 
2018-03-06 11:10:41	msbrown3	Make a table with (specialist id, disease id, pubmed id) 
2018-03-06 11:11:45	msbrown3	for each of the IDs, either use a foreign key to the table, or use a unique id that won't change (like use id_orpha instead of id for disease) 
2018-03-06 11:14:21	jesse	sounds good except for the disease id part. Our data only has the disease name, which was obtained from the diseases.txt file that we weren't supposed to be using anymore. I never went back to change that part since it would take 24ish hours to generate the pubmed articles. Also, some of the articles would have multiple rare diseases associated with it. Would you be ok if that column was a list of the disease id's or disease names? 
2018-03-06 11:17:29	jesse	:cry: 
2018-03-06 11:18:46	msbrown3	the names are actually different in there. can you regenerate the pubmed data so you can get the disease IDs? even though it will take a while we need the names to match 
2018-03-06 11:19:13	msbrown3	just curious, what id are you going to use for specialists? 
2018-03-06 11:19:53	jesse	NPI I would assume. 
2018-03-06 11:21:22	msbrown3	ok, NPI sounds good 
2018-03-06 11:24:01	jesse	And as for regenerating the pubmed data, should we query on the disease name like we did before? or try to query on the mesh terms? Mesh terms would be a  larger set of data. 
2018-03-06 11:25:29	jesse	but we also don't have all of the mesh terms 
2018-03-06 11:26:11	msbrown3	yeah. If it's not hard, you can MeSH if we have it and search disease name as a backup 
2018-03-06 11:26:23	msbrown3	but for now it's not a big deal if you just want to do disease name 
2018-03-06 11:27:56	jesse	I think I'll go with the disease name... I'm not sure how hard that stuff is going to be, and I'm a lil worried about ram for making the files haha. 
2018-03-06 11:28:21	msbrown3	haha. ok. we can always make those refinements later 
2018-03-06 11:28:50	jesse	sounds good. 
2018-03-06 11:29:35	jesse	rarediseases_disease is where I should get the data from right? 
2018-03-06 11:29:46	msbrown3	yes 
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 10:18:32		getting channel history...
2018-03-06 11:02:08	jesse	Hey Michael, when I find a link between the last name and the medical school name between the pubmed authors and the specialists, where should I put the new column (in specialists?)? and should that new column be the pmid's of the articles that they published? or would you just want the associated rare disease? 
2018-03-06 11:05:10	jesse	I'm thinking the PMID's of the articles would be best. then we can query on the PMID's associated with a rare disease, and then query the specialists who worked on a particular PMID. 
2018-03-06 11:05:26	jesse	Do you have thoughts? 
2018-03-06 11:06:54	msbrown3	yes. I have thoughts 
2018-03-06 11:07:17	jesse	:slightly_smiling_face: 
2018-03-06 11:08:03	msbrown3	do you have a unique id for each specialist? 
2018-03-06 11:09:00	jesse	I'll check but I'm pretty certain that is a yes. 
2018-03-06 11:10:17	msbrown3	ok. I think the best way to store it is this: 
2018-03-06 11:10:24	jesse	yup 
2018-03-06 11:10:37	jesse	^ as in we do have a unique id for each specialist 
2018-03-06 11:10:41	msbrown3	Make a table with (specialist id, disease id, pubmed id) 
2018-03-06 11:11:45	msbrown3	for each of the IDs, either use a foreign key to the table, or use a unique id that won't change (like use id_orpha instead of id for disease) 
2018-03-06 11:14:21	jesse	sounds good except for the disease id part. Our data only has the disease name, which was obtained from the diseases.txt file that we weren't supposed to be using anymore. I never went back to change that part since it would take 24ish hours to generate the pubmed articles. Also, some of the articles would have multiple rare diseases associated with it. Would you be ok if that column was a list of the disease id's or disease names? 
2018-03-06 11:17:29	jesse	:cry: 
2018-03-06 11:18:46	msbrown3	the names are actually different in there. can you regenerate the pubmed data so you can get the disease IDs? even though it will take a while we need the names to match 
2018-03-06 11:19:13	msbrown3	just curious, what id are you going to use for specialists? 
2018-03-06 11:19:53	jesse	NPI I would assume. 
2018-03-06 11:21:22	msbrown3	ok, NPI sounds good 
2018-03-06 11:24:01	jesse	And as for regenerating the pubmed data, should we query on the disease name like we did before? or try to query on the mesh terms? Mesh terms would be a  larger set of data. 
2018-03-06 11:25:29	jesse	but we also don't have all of the mesh terms 
2018-03-06 11:26:11	msbrown3	yeah. If it's not hard, you can MeSH if we have it and search disease name as a backup 
2018-03-06 11:26:23	msbrown3	but for now it's not a big deal if you just want to do disease name 
2018-03-06 11:27:56	jesse	I think I'll go with the disease name... I'm not sure how hard that stuff is going to be, and I'm a lil worried about ram for making the files haha. 
2018-03-06 11:28:21	msbrown3	haha. ok. we can always make those refinements later 
2018-03-06 11:28:50	jesse	sounds good. 
2018-03-06 11:29:35	jesse	rarediseases_disease is where I should get the data from right? 
2018-03-06 11:29:46	msbrown3	yes 
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 15:48:04		getting channel history...
2018-03-06 11:10:37	jesse	^ as in we do have a unique id for each specialist 
2018-03-06 11:10:41	msbrown3	Make a table with (specialist id, disease id, pubmed id) 
2018-03-06 11:11:45	msbrown3	for each of the IDs, either use a foreign key to the table, or use a unique id that won't change (like use id_orpha instead of id for disease) 
2018-03-06 11:14:21	jesse	sounds good except for the disease id part. Our data only has the disease name, which was obtained from the diseases.txt file that we weren't supposed to be using anymore. I never went back to change that part since it would take 24ish hours to generate the pubmed articles. Also, some of the articles would have multiple rare diseases associated with it. Would you be ok if that column was a list of the disease id's or disease names? 
2018-03-06 11:17:29	jesse	:cry: 
2018-03-06 11:18:46	msbrown3	the names are actually different in there. can you regenerate the pubmed data so you can get the disease IDs? even though it will take a while we need the names to match 
2018-03-06 11:19:13	msbrown3	just curious, what id are you going to use for specialists? 
2018-03-06 11:19:53	jesse	NPI I would assume. 
2018-03-06 11:21:22	msbrown3	ok, NPI sounds good 
2018-03-06 11:24:01	jesse	And as for regenerating the pubmed data, should we query on the disease name like we did before? or try to query on the mesh terms? Mesh terms would be a  larger set of data. 
2018-03-06 11:25:29	jesse	but we also don't have all of the mesh terms 
2018-03-06 11:26:11	msbrown3	yeah. If it's not hard, you can MeSH if we have it and search disease name as a backup 
2018-03-06 11:26:23	msbrown3	but for now it's not a big deal if you just want to do disease name 
2018-03-06 11:27:56	jesse	I think I'll go with the disease name... I'm not sure how hard that stuff is going to be, and I'm a lil worried about ram for making the files haha. 
2018-03-06 11:28:21	msbrown3	haha. ok. we can always make those refinements later 
2018-03-06 11:28:50	jesse	sounds good. 
2018-03-06 11:29:35	jesse	rarediseases_disease is where I should get the data from right? 
2018-03-06 11:29:46	msbrown3	yes 
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:55:03		getting channel history...
2018-03-06 11:10:41	msbrown3	Make a table with (specialist id, disease id, pubmed id) 
2018-03-06 11:11:45	msbrown3	for each of the IDs, either use a foreign key to the table, or use a unique id that won't change (like use id_orpha instead of id for disease) 
2018-03-06 11:14:21	jesse	sounds good except for the disease id part. Our data only has the disease name, which was obtained from the diseases.txt file that we weren't supposed to be using anymore. I never went back to change that part since it would take 24ish hours to generate the pubmed articles. Also, some of the articles would have multiple rare diseases associated with it. Would you be ok if that column was a list of the disease id's or disease names? 
2018-03-06 11:17:29	jesse	:cry: 
2018-03-06 11:18:46	msbrown3	the names are actually different in there. can you regenerate the pubmed data so you can get the disease IDs? even though it will take a while we need the names to match 
2018-03-06 11:19:13	msbrown3	just curious, what id are you going to use for specialists? 
2018-03-06 11:19:53	jesse	NPI I would assume. 
2018-03-06 11:21:22	msbrown3	ok, NPI sounds good 
2018-03-06 11:24:01	jesse	And as for regenerating the pubmed data, should we query on the disease name like we did before? or try to query on the mesh terms? Mesh terms would be a  larger set of data. 
2018-03-06 11:25:29	jesse	but we also don't have all of the mesh terms 
2018-03-06 11:26:11	msbrown3	yeah. If it's not hard, you can MeSH if we have it and search disease name as a backup 
2018-03-06 11:26:23	msbrown3	but for now it's not a big deal if you just want to do disease name 
2018-03-06 11:27:56	jesse	I think I'll go with the disease name... I'm not sure how hard that stuff is going to be, and I'm a lil worried about ram for making the files haha. 
2018-03-06 11:28:21	msbrown3	haha. ok. we can always make those refinements later 
2018-03-06 11:28:50	jesse	sounds good. 
2018-03-06 11:29:35	jesse	rarediseases_disease is where I should get the data from right? 
2018-03-06 11:29:46	msbrown3	yes 
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:52:18		getting channel history...
2018-03-06 12:07:12	jesse	Hey michael, how did we get 6000 diseases in that one rare diseases txt file and 19000 in the table? are many of them synonyms? 
2018-03-06 12:09:09	jesse	I may run into issues with storage and ram usage since 6000 diseases produced 8.5 gigs of output. I modified the program so that it would output a file after every 100 diseases it passed through, but filtering out the duplicates may be a huge problem with that many diseases. 
2018-03-06 12:20:30	msbrown3	aren't there 9601 diseases in the db? 
2018-03-06 12:20:58	msbrown3	some of them are actually categories, so you don't need to make queries for those 
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:42:52		getting channel history...
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 10:04:56		getting channel history...
2018-03-06 12:23:20	msbrown3	when you get diseases, only get ones with is_category=False, is_historical=False, is_deprecated=False 
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-20 20:42:29		getting channel history...
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 07:56:25		getting channel history...
2018-03-06 12:45:20	jesse	oh okay. Thanks michael 
2018-03-06 13:39:31	jesse	yeah there were about 7000ish when I added those parts of the query. I got 19000 because when I outputted to a csv, I just counted the lines in the file... I could have misread the number 9000. Idk but the script has been goin. 
2018-03-06 13:41:21	msbrown3	ok 
2018-03-06 13:42:25	msbrown3	There are synonyms in the rarediseases_disease table if you're dumping all the fields in there. It's a textfield with newlines separating synonyms, so you might get more lines because of that depending on how you're dumping stuff 
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 11:58:29		getting channel history...
2018-03-06 13:45:49	jesse	I was just going to query each of the names (from the name column) in that table. If there are synonyms amongst that, then they will likely be duplicates which my other program will be able to filter out 
2018-03-06 13:46:21	jesse	I'm not using the csv anymore. I'm just querying psql directly 
2018-03-06 13:48:23	jesse	so as long as the names column is just the name of the disease and not dealing with funky stuff like synonyms within the same row, I think we'll be good 
2018-03-06 13:52:47	msbrown3	yea. names are just names. synonyms are another column, but probably don't need to query for synonyms at all 
2018-03-06 13:55:04	jesse	oh I forgot to record the id of the disease. 
2018-03-06 13:55:15	jesse	:P 
2018-03-06 13:55:26	msbrown3	haha, whops that's important 
2018-03-06 13:57:42	jesse	yeah its like the whole reason we wanted to run it again haha. i was focusing more on making the program run on its own and execute from start to finish writing out to multiple files rather than requiring text files being piped in and out. 
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-21 14:20:11		getting channel history...
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-25 17:14:14		getting channel history...
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:25:23		getting channel history...
2018-03-06 13:58:17	jesse	does every disease have an orpha_id? 
2018-03-06 13:58:30	msbrown3	yes 
2018-03-06 13:59:23	msbrown3	other IDs are not always, but id_orpha is always there because that's the main place we're getting the data 
2018-03-06 14:15:04	jesse	Gotcha. Its running now. and itll fetch the orpha id this time xD 
2018-03-06 14:15:20	msbrown3	awesome! 
2018-03-06 14:15:57	msbrown3	:+1: 
2018-03-06 17:39:44	jesse	hey michael, would you or meaghan be able to help me out with comparing the medical schools? there are 636401 authors associated with various articles in pubmed and there are 2645234 specialists to compare. If I try with a nested for loop to compare them, it would take 1683.5 billion comparisons which is far more than my computer can handle in a reasonable amount of time. I also wanted to do something with ngrams since the med schools are not written in the same way in each of the 2 data sets... but that would only add to the complexity.
2018-03-06 17:39:44		Do you have any ideas for getting past this?
2018-03-06 17:39:44		My thought was that I could take a list of the non-duplicated medical schools based on the specialists data set (404 entries) and compare that to the affiliations. However, that wouldn't help much with the overall goal, since we need which physicians go to those med schools... 
2018-03-06 17:42:44	jesse	I guess if we had some sort of dictionary that could translate the pubmed medschool to the specialist medschool, something like this could be accomplished much quicker... but I'm not sure how to go about making something like that. 
2018-03-06 17:54:31	jesse	and we still need to compare the physicians last name...  so we couldn't just get a list of NPIs per med school and then compare the med schools in pubmed. 
2018-03-07 10:14:25	msbrown3	Don't bother with the ngrams for now, we just need something by the end of the week, even if it's not all the results 
2018-03-07 10:15:13	msbrown3	Just search for the 404 medical schools you have in PubMed. As long as it gives some results, it's good enough for now 
2018-03-07 10:15:53	msbrown3	Megan is working on getting the duplicated specialists out. There will be only 1 million of those when that's done 
2018-03-07 10:20:25	msbrown3	if it makes it easier to not include the pubmed id in the final data, you can make that simplification 
2018-03-07 10:25:53	msbrown3	I think there's a way to do this in linear time.... build a dictionary of pubmed authors, then go through each specialist and do lookups on that dictionary to match them 
2018-03-07 10:26:39	jesse	uhh which duplicated specialists? I may have already done that work. 
2018-03-07 10:27:25	jesse	For the pubmed data or the 'specialists' data? 
2018-03-07 10:27:32	msbrown3	specialists 
2018-03-07 10:27:41	msbrown3	I think it was specialists that were exactly the same except for location 
2018-03-07 10:28:18	jesse	That's weird. Did we ever switch to the http://medicare.gov (medicare.gov) dataset for the specialists? 
2018-03-07 10:28:39	jesse	or are you guys still using the specialists from just NC? 
2018-03-07 10:28:56	msbrown3	still the ones from NC 
2018-03-07 10:29:11	jesse	:disappointed: 
2018-03-07 10:30:27	jesse	If we used the http://medicare.gov (medicare.gov) data, we wouldn't have to worry about the drug companies (and im guessing duplicates as well) but I'm not entirely sure. 
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 10:25:44		getting channel history...
2018-03-07 10:31:29	msbrown3	wait, nvm 
2018-03-07 10:32:30	msbrown3	Megan says we're not using the NC specialists anymore. It's from some dataset you gave here in the "for meghan" folder 
2018-03-07 10:33:39	msbrown3	so I'm assuming that was from http://medicare.gov (medicare.gov)? 
2018-03-07 10:34:54	jesse	yup. 
2018-03-07 10:35:00	jesse	so there are duplicates amongst that? 
2018-03-07 10:35:47	msbrown3	yes 
2018-03-07 10:36:03	jesse	:cry: 
2018-03-07 10:37:29	msbrown3	yea. I'm looking at the dataset online, just seems to be how it's organized, with a physician having entries for every one of their locations 
2018-03-07 10:42:05	jesse	Thats a bummer. I don't think that stuff is going to affect the way I'm comparing the medical schools though. maybe itll cause duplicate entries in my data when it actually starts generating. I'm just workin on getting more and more matches from the med schools so I know how to compare them. 
2018-03-07 10:45:04	jesse	hey Michael, does python free memory allocated from variables when the variables are overwritten? 
2018-03-07 10:46:10	msbrown3	If there are no more references to the object, it will usually free that memory 
2018-03-07 10:47:26	msbrown3	there can be circular references that get garbage collected later, but if there's only one reference and you take that reference away (for example by reassigning the variable) then it'll free it 
2018-03-07 10:48:56	jesse	If a variable carries with it 2.5 gigs of data, and within the loop, I set the variable to nothing so it can generate 2.5 gigs more data, does the initial 2.5 gigs of data stay in  memory? 
2018-03-07 10:49:32	jesse	would that be the circular references thing you mentioned? 
2018-03-07 10:51:58	msbrown3	only if the data has circular references in it 
2018-03-07 10:52:39	jesse	could you give me an example of a circular reference? 
2018-03-07 10:53:03	jesse	this may impact the pubmed generator that's running :stuck_out_tongue: 
2018-03-07 10:55:47	msbrown3	@msbrown3 uploaded a file: https://ncstateuniversityitng.slack.com/files/U8S9XT8CW/F9M4B0D47/Circular_Reference.py (Circular Reference) 
2018-03-07 10:59:16	jesse	ah gotcha. the python program  is at 6.92 gigs out of 7.64 gigs memory usage right now and doesn't seem to be gaining any memory or losing memory, and yet the program is still going. Which is weird to me. I'm not sure if some python garbage collector is going to reclaim the old memory that isn't being used or if its just overwriting memory that was previously allocated. 
2018-03-07 10:59:57	jesse	if python is like C, then the latter may actually be a possibility. ^ 
2018-03-07 11:00:38	msbrown3	yeah, it's a definite possibility, since python is written in C 
2018-03-07 11:00:54	msbrown3	Sometimes it's hard to tell what's going on under the hood 
2018-03-07 11:02:06	jesse	neat!  I have it outputting to multiple files so if theres a problem, I can probably just start it where it left off without much time loss. 
2018-03-07 11:02:15	msbrown3	cool 
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-05 13:46:56		getting channel history...
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 12:58:13		getting channel history...
2018-03-07 11:02:41	jesse	11hrs at 64% in case you were curious. 
2018-03-07 11:02:53	msbrown3	wow 
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access.  
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:01		getting channel history...
2018-03-07 11:04:04	msbrown3	So what exactly is being matched with the medical schools? I see the medical school name in the physician data, but that's where they went to school, not where they currently are? Or is that what we want, papers they published while they were in school? 
2018-03-07 11:11:03	jesse	what I mentioned a second ago was the pubmed data being collected... separate from those connections..
2018-03-07 11:11:03		I would hope that if the physician is working at a hospital, they would not be currently in a medical school. Therefore, the medical school name is where they went to school, and are not currently associated. As for when the papers were published. I'm not sure yet whether it matters or what would be accounted for in that case. pubmed may be listing the medical schools simply based on where the author went to school...  they list them as 'Affiliations' so even if the author is no longer still with the school, they could still have that school listed under affiliations.
2018-03-07 11:11:03		Does that answer your question? basically, it's an ' i dont know ' haha. 
2018-03-07 11:13:12	msbrown3	yeah that makes sense 
2018-03-08 07:02:53	jesse	were you guys still planning on having a meeting at 10? 
2018-03-08 07:07:02	jesse	if you guys would like me to attend, I can join in through hangouts on someone's computer. I wasn't sure what you guys' plan was. 
2018-03-08 07:26:53	msbrown3	nope, no meeting 
2018-03-08 07:27:19	msbrown3	Meaghan and I are around though. 
2018-03-08 07:27:57	jesse	gotcha. Last week there was some mention of possibly having some optional meeting so I was wonderin. Thanks Michael! 
2018-03-08 07:47:59	msbrown3	np 
2018-03-08 08:55:43	jesse	Hey Michael, would I be able to get whether the orpha_id of a particular disease was a category, deprecated, or historical?
2018-03-08 08:55:43		I think when I ran the pubmed crawler again I forgot to add those 3 fields, and I only noticed now as the progress bar has exceeded 100%. 
2018-03-08 08:57:16	jesse	but the progress bar accounted for is_category, deprecated, and historical being False... so I'm just an idiot lol 
2018-03-08 08:57:48	msbrown3	oh, so were doing more work than your progress bar thought 
2018-03-08 08:58:12	msbrown3	shouldn't hurt anything to include diseases where is_category=True, (or the others), it'll just take longer 
2018-03-08 08:58:54	jesse	ok. If you want those values removed, then I could build something into my removeDuplicates scripts that removes those diseases 
2018-03-08 08:59:38	msbrown3	doesn't matter to me 
2018-03-08 09:00:07	jesse	aight. Guess I'll just leave them in. 
2018-03-08 09:02:12	jesse	its kinda funny to watch a progress bar go passed 100% though. I'm imagining the screen flashing red as if something is going to break haha 
2018-03-08 09:02:50	msbrown3	haha, yeah 
2018-03-08 09:03:18	msbrown3	so is the matching working out okay? 
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how ghr.nlm.nih.gov is different from rarediseases.info.nih.gov? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-11 09:38:49		getting channel history...
2018-03-08 09:04:19	jesse	for the specialists to pubmed articles? 
2018-03-08 09:04:49	msbrown3	yeah 
2018-03-08 09:08:54	jesse	I got 642 matches on the old dataset. The new dataset is still building, sadly. I had to limit my scope to NC only. I'm thinking if I can get all of the states for the medical schools that show up within the physician data, then I could do something similar by repetitively building SQL statements and comparing only the outputs. I'm estimating a script like that would take 24 hours since the NC med schools took around 30 minutes and there are 50 states.  I'm not sure we should do anything special like n-grams though. something like that might make the run-time much longer and I'm not certain it would yield a lot more output. 
2018-03-08 09:11:41	jesse	but just out of the 404 medical schools that appears in the specialists data, we were able to find matches for a lil over 200 of them just by taking out unnecessary words... but if the pubmed data is inconsistent with how they are naming the med schools, then we may have to deal with the ngrams. 
2018-03-08 09:12:59	jesse	btw, I have a separate script for just comparing hospitals vs comparing the specialist and the pubmed stuff... I figured it would come in handy for the sake of knowing how many hospitals would match and maybe trying to get that number higher. 
2018-03-08 09:14:11	msbrown3	the old dataset being the pubmed queries before the specialists were de-duplicated? Is the new dataset going to have strictly less matches? because 642 doesn't seem like a lot 
2018-03-08 09:19:22	jesse	the old dataset being when I generated everything based off of diseases.txt rather than the psql table.
2018-03-08 09:19:22		more diseases means more possible connections but i would assume it to be in the 1000ish area give or take a few hundred since there are about double the diseases. and this is just NC.
2018-03-08 09:19:22		I'm gonna be looking more into how pubmed stores there med schools and what I can do to raise that number.
2018-03-08 09:19:22		also, we are matching based on last name as well. if the person doesnt exist on the physician data set, they won't show up on the connections. 
2018-03-08 09:20:10	msbrown3	ok 
2018-03-08 09:22:38	jesse	im also not sure how many physicians publish papers recognized by pubmed. and how many of those papers would be about a rare disease. i don't suppose they would be rare if everyone published papers on them. but yeah, the goal is to get the number higher. 
2018-03-08 09:24:57	jesse	also, if you want, I can push my comparison scripts as well as send you the csvs associated if you wanted to take a look. 
2018-03-08 09:27:38	msbrown3	yeah. when you have everything running the way you want it. which it sounds like you do 
2018-03-08 09:30:36	jesse	Not exactly, but it is definitely running :stuck_out_tongue: you may need my multi-gigabyte dataset though to run it. I've been using a local database. 
2018-03-08 09:31:44	jesse	I'm pretty sure its already on power6a (the csv, not the tables since meaghan dropped them a lil while ago.) 
2018-03-08 09:39:42	jesse	I pushed the scripts. 
2018-03-08 09:40:29	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9MNZTGG7/yetanotherlistofmedschools.csv (YetAnotherListOfMedSchools.csv) and commented: List of Med schools that appeared in the physician data. I made a few types of these lists, but this one is most relevant. 
2018-03-08 09:41:01	msbrown3	awesome, thanks 
2018-03-08 09:42:46	jesse	in power6a, I stored the csvs of the data at this location: /home/jlsimps4/ForMeaghan/Pubmed
2018-03-08 09:42:46		My scripts take postgres stuff so they would need to be converted into a table in a database... 
2018-03-08 09:43:01	jesse	I can do that real quick if you'd like. 
2018-03-08 09:45:29	msbrown3	no, that's fine. I probably won't run anything, it's just good to see how it works and see the data 
2018-03-08 09:46:01	jesse	gotcha. I've got some more outputs if you'd like to see those. That list ^^ is just the input. 
2018-03-08 09:51:08	msbrown3	yeah, if it's not much work to put them on power6a, it would be good to look at 
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:38:58		getting channel history...
2018-03-08 09:55:50	jesse	ok, you should find them under /home/jlsimps4/ForTheGreatAndPowerfulMichael/ 
2018-03-08 09:56:25	msbrown3	haha. thanks 
2018-03-08 09:58:15	jesse	do i need to mess with any privileges so you can see it? 
2018-03-08 09:59:12	msbrown3	nope, I can see all =P 
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-14 15:33:41		getting channel history...
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-14 16:42:10		getting channel history...
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-14 17:17:28		getting channel history...
2018-03-08 09:59:26	jesse	xD 
2018-03-08 09:59:29	jesse	cool 
2018-03-08 09:59:33	msbrown3	(after asking meaghan for access) 
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 16:34:23		getting channel history...
2018-03-08 10:01:25	jesse	HAHAHAHAHA THATS GREAT!! did you ask her access to that folder specifically? 
2018-03-08 10:02:54	msbrown3	no, she just gave me root. I might go and change the permissions myself so I don't have to be root to see it though 
2018-03-08 10:04:01	jesse	that's fine. as long as I dont end up with folders in my home directory that I cant access 
2018-03-08 10:04:20	msbrown3	haha. no I won't do that 
2018-03-08 16:12:31	jesse	i screwed up. turns out the orpha id was repetitively overwritten cuz of a dumb line of code that shouldn't have existed... :( 
2018-03-08 16:17:32	msbrown3	D= 
2018-03-08 16:18:03	msbrown3	do you just have to re-run it overnight? 
2018-03-08 16:21:04	jesse	yeah. this time, i made it so that its not fetching the historical or deprecated stuff. and the output is gonna be directly in postgres(on my VMs database) so I dont think I will need to worry much about annoying memory problems or file concatenation or sorting.... on the brightside, this process is getting more and more automated. 
2018-03-08 16:29:12	msbrown3	cool 
2018-03-13 13:43:09	msbrown3	CREATE INDEX ix_specialists_last_name on specialists USING btree(last_name);
2018-03-13 13:43:09		CREATE INDEX ix_pubmed_authors_last_name on pubmed_authors USING btree(last_name); 
2018-03-13 15:25:24	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/F9NL1ECCQ/pubmed_physician.csv (pubmed_physician.csv) 
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 11:51:27		getting channel history...
2018-03-13 15:25:55	jesse	autoid, disease_orpha_id, pmid,  specialist_npi 
2018-03-13 18:15:23	msbrown3	You'll need to check that the first names match in your script. 
2018-03-13 19:15:39	jesse	first names currently include the middle initial I think... but thats easy to check 
2018-03-14 09:44:47	msbrown3	Meaghan said pubmed usually only has first letter of the first name. Maybe we can check if the full name exists and match on that, but just do the first letter if that's all there is? 
2018-03-14 09:46:18	msbrown3	When you get a chance to update the script maybe you can send me a few hundred rows of new sample data 
2018-03-14 09:47:12	msbrown3	Meaghan is almost done with the specialists deduplication. 
2018-03-14 09:50:26	jesse	I was talking to sagar about that last night, he told me he would add that exact code. I'm not sure if he did or not. 
2018-03-14 09:50:58	msbrown3	okay, cool 
2018-03-14 10:12:27	jesse	He didn't push so I just made the five lines of code. It's running now. I didn't test the output because I'm working on other things right now. (sorry). I'll send you the output when its done. 
2018-03-14 10:13:04	msbrown3	ok great :+1::skin-tone-3: 
2018-03-14 10:13:20	jesse	uhh... i only got 12 connections out of 500 last names.... 
2018-03-14 10:13:39	jesse	autoid | disease_orpha_id |   pmid   | specialist_npi 
2018-03-14 10:13:39		--------+------------------+----------+----------------
2018-03-14 10:13:39		      0 |           254902 |  8007040 |     1316948698
2018-03-14 10:13:39		      1 |            70578 |  8007040 |     1316948698
2018-03-14 10:13:39		      2 |            91130 |  8007040 |     1316948698
2018-03-14 10:13:39		      3 |              732 |  3479931 |     1043236359
2018-03-14 10:13:39		      4 |            48918 |  3479931 |     1043236359
2018-03-14 10:13:39		      5 |              520 | 11435292 |     1043292246
2018-03-14 10:13:39		      6 |           447771 | 10980934 |     1699726547
2018-03-14 10:13:39		      7 |              171 | 10980934 |     1699726547
2018-03-14 10:13:39		      8 |           243367 | 10808029 |     1699726547
2018-03-14 10:13:39		      9 |            70567 | 10980934 |     1699726547
2018-03-14 10:13:39		     10 |            90062 | 10808029 |     1699726547
2018-03-14 10:13:39		     11 |              186 | 10980934 |     1699726547 
2018-03-14 10:14:22	jesse	I think (and kinda hope )that means theres a bug in what I wrote... 
2018-03-14 10:16:30	msbrown3	I wonder if that's those are the only real connections? I mean, there's some ground truth in how many of these specialists published papers about a disease 
2018-03-14 10:23:43	jesse	perhaps. and we've got plenty of other last names.... but its also possible that my code is removing connections where the name is only one letter long. 
2018-03-14 17:32:04	msbrown3	So what's your status now. Are you running the script on everythnig, or still making sure there aren't any bugs in the name comparison? 
2018-03-14 17:56:08	jesse	I haven't done anything since I sent you the above data. Sagar was messaging me and seemed to suggest he might be testing the program, but I'm not sure if he actually did that or not. 
2018-03-14 17:57:06	jesse	I can test and run the program later tonight if you'd like, so that we can have something to show tomorrow, but right now, I'm with another group working on a project. 
2018-03-14 17:57:30	jesse	I pushed the code so you are more than welcome to look at it too. 
2018-03-14 17:58:13	jesse	sorry i haven't been available today. mondays and wednesdays are usually busy for me. 
2018-03-14 19:34:51	jesse	turns out 3/4ths of the first_name entries are empty strings so I'm thinking that those authors are being ignored.... 
2018-03-14 19:35:18	msbrown3	3/4 of the pubmed authors? 
2018-03-14 19:35:24	jesse	Yessir! 
2018-03-14 19:35:52	msbrown3	wow, that is many. Not sure if we can compare reliably without a first name 
2018-03-14 19:36:41	jesse	Dr. Kowolenko previously just told us to compare just last names and med schools since we had only the initials of the first name for most entries... sadly, we aren't even getting the first initial. 
2018-03-14 19:38:01	msbrown3	okay. Personally I don't think we'll get very good connections without more name info, but we can always improve it later. 
2018-03-14 19:38:36	msbrown3	how close are you to running it with just ignoring first names if theye're not there? 
2018-03-14 19:39:21	jesse	I can do that in one line of code with the rest of what I have. 
2018-03-14 19:40:49	msbrown3	ok. if you can start that soon, we can at least say we have the connections the way mike suggested. We'll look to see if it's good enough later 
2018-03-14 19:43:27	jesse	We also need to improve the med school search. I thought about making a system where we remove the prepositional phrases and sort the words of the med school names and then check if the words of in the specialists are within the words of the pubmed authors. Does that seem like a decent way to compare the med schools? 
2018-03-14 19:45:21	msbrown3	I haven't seen the data enough to really know 
2018-03-14 19:48:56	jesse	okay. I'm not too familiar with n-grams but I hear those are good too. 
2018-03-14 19:50:40	msbrown3	What I would like is a script that doesn't even mess with specialists or pubmed articles, but shows matches on the medschools. Then we can just try a bunch of things quickly and print some results to see what works for matching medschools 
2018-03-14 19:51:16	msbrown3	but before that, we just need something to match specialists and diseases, as long as it is somewhat sensible 
2018-03-14 19:57:57	jesse	I think i was lying about the first name only being initials thing... printing it out in python gets different results than sql searching 
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-20 16:04:20		getting channel history...
2018-03-14 20:00:12	msbrown3	hmm, yeah. I'm seeing ~63% of pubmed_authors with length(first_name) > 2 
2018-03-14 20:00:30	msbrown3	not sure if we have the same dataset exactly 
2018-03-14 20:00:52	jesse	turns out that I wasn't comparing the first names using uppercase letters. 
2018-03-14 20:01:23	msbrown3	so you weren't doing it case insensitive? 
2018-03-14 20:03:02	jesse	yeah... but now its only 26 connections... i'm sure I have another bug in there. 
2018-03-14 20:05:35	msbrown3	ok. let me know if I can help. We can meet before/after the meeting tomorrow if you want to work through anything 
2018-03-14 20:07:02	jesse	sure thing! 
2018-03-14 20:09:41	jesse	it seems the first name and last name comparison is good... but it must be failing on the med school connections. 
2018-03-14 20:26:40	jesse	it seems you guys don't have python3 on power6a so I cant run my script 
2018-03-14 20:26:58	jesse	I'll run it on my VM. 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:30	msbrown3	Oh, I guest that's a centos machine 
2018-03-14 20:37:35	msbrown3	Power6a that is 
2018-03-15 09:59:52	msbrown3	https://dba.stackexchange.com/questions/33943/granting-access-to-all-tables-for-a-user#33960
2018-03-15 09:59:52		Granting access to all tables for a user
2018-03-15 09:59:52		I'm a new to Postgres and trying to migrate our MySQL databases over. In MySQL I can grant SELECT, UPDATE, INSERT, DELETE privileges on a low privileged user and enable those grants to apply to all 
2018-03-17 13:28:20	jesse	hey michael, what was the index you had me make to speed up the pubmed connections program? was it just on the last names? 
2018-03-17 13:31:50	msbrown3	I don't remember exactly do you have the psql history 
2018-03-17 13:31:52	msbrown3	? 
2018-03-17 13:32:36	msbrown3	it was something like "CREATE INDEX ix_pubmed_authors_last_lower on pubmed_authors USING btree(lower(last));" 
2018-03-17 13:33:01	msbrown3	Maybe a siimlar one for first names? If you show me your SQL queries I can probably figure out what indexes would speed it up 
2018-03-17 13:34:50	jesse	i forgot lower haha. now its speeding up haha 
2018-03-17 13:35:55	msbrown3	yay 
2018-03-17 13:40:10	jesse	I also inserted my better version of matching med schools. idk how much thatll help though cuz my testing script only looked at 62500 authors... but it seemed better and pretty accurate. 
2018-03-17 13:40:32	jesse	I'll let you guys know when it finishes 
2018-03-17 15:49:39	jesse	It finished. I got 32,000 results 
2018-03-19 09:56:38	jesse	Hey Michael, Does the rare disease website run on python2 now? it seems to use pyzipcode which seems to be a python2 package. 
2018-03-19 10:01:12	jesse	Sorry, the error message was throwing me for a loop. I think pyzipcode may be using pysqlite, which python3 doesn 
2018-03-19 10:01:17	jesse	t seem to like.  
2018-03-19 10:10:53	msbrown3	did you install pip requirements using requirements.txt? 
2018-03-19 10:11:28	msbrown3	there are confusingly two versions of the pyzipcode package, the one in requirements.txt should be the correct one for python3 
2018-03-19 10:14:19	jesse	I'll give it a try 
2018-03-19 10:16:47	msbrown3	cool. make sure to uninstall pyzipcode before installing pyzipcode3. 
2018-03-19 10:17:42	jesse	is there a way to pip install everything in the requirements.txt? 
2018-03-19 10:17:59	msbrown3	`pip install -r requirements.txt` 
2018-03-19 10:18:19	jesse	hahaha and here I was going to use cat and pipes 
2018-03-19 10:18:55	msbrown3	heh, yeah that sounds harder 
2018-03-19 10:34:01	jesse	things still arent running right. you mind if I come by the lab in a bit and get either you or meaghan to take a look. I'm probably just forgetting something dumb. 
2018-03-19 10:34:17	msbrown3	yeah, no problem 
2018-03-19 10:34:25	jesse	cool 
2018-03-19 10:34:31	msbrown3	We have a meeting at 11, but after 12 we'll be available 
2018-03-19 11:04:14	jesse	Dang lol i was gonna come now cuz i have a class on main at 11:45 and another at 3. 
2018-03-19 11:04:46	jesse	that's okay though 
2018-03-19 16:10:44	jesse	are you guys still at the lab? 
2018-03-19 16:10:56	msbrown3	Meaghan left, I'm still here though 
2018-03-19 16:11:19	jesse	cool. i can be there in a couple mins 
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows) 
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:58		getting channel history...
2018-03-19 16:11:29	msbrown3	cool, come on over! 
2018-03-20 11:01:17	jesse	the whole database minus the pubmed junk is like 700MB lol. I thought you were exaggerating. 
2018-03-21 11:48:50	jesse	Hey Michael, do you know who made the rarediseases_diseasephenotypes table? 
2018-03-21 11:49:09	jesse	or where that script is? 
2018-03-21 11:50:14	jesse	nvm I think I found the script 
2018-03-21 12:10:33	msbrown3	yeah, I made that one 
2018-03-21 12:11:34	msbrown3	rarediseases_diseasephenotypes is the link between diseases and phenotypes. It should have a foreignkey to a disease and a phenotype, along with the frequency data 
2018-03-21 12:16:08	jesse	gotcha. I was having some strange behavior where some phenotypes should have the SSA link but didn't. I think this has something to do with how the symptoms generated for each disease checks subdiseases in the django stuff but maybe not the db... or something... I've got a few ideas of how to fix my code, so don't worry about correcting me haha. 
2018-03-21 12:17:15	msbrown3	SSA? 
2018-03-21 12:17:44	msbrown3	The symptoms don't check sub-diseases at all, that data is straight from orphanet/hpo for each disease 
2018-03-21 12:19:26	jesse	SSA: that dummy link I have next to some of the phenotypes 
2018-03-21 12:20:36	msbrown3	ok 
2018-03-21 12:25:48	jesse	I might come back to the lab if you're there later around 4ish if I can't figure it out on my own inbetween classes. 
2018-03-21 12:26:05	msbrown3	ok, I should be here 
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:41:54		getting channel history...
2018-03-31 15:26:20	jesse	I never got around to checking if the new pubmed articles were valid or not. Did you have any specific diseases/articles that you know were incorrect before? 
2018-04-01 09:55:02	msbrown3	I'm trying to remember.... I know there was one that had ~50 results on pubmed that weren't all that related 
2018-04-01 09:56:38	msbrown3	"Multiple epiphyseal dysplasia, Al-Gazali type" 
2018-04-01 09:59:21	msbrown3	It matched on authors with "Al-Gazali" on the name. 
2018-04-01 09:59:54	msbrown3	It looks like (at least the pubmed data on my dev machine) we don't have all the authors for some articles 
2018-04-01 10:00:04	jesse	oh... I'm not sure our thing would fix that or not. 
2018-04-01 10:03:47	msbrown3	ok. I guess we haven't seen any way to search pubmed that doesn't match on the author 
2018-04-01 10:06:46	jesse	well, if Multiple epiphyseal dysplasia, Al-Gazali type [MeSH Terms] doesnt get any results, itll go back and do a text based search.
2018-04-01 10:06:46		I'm not sure which search it tried. 
2018-04-01 10:08:49	jesse	I'm not sure if the [MeSH Terms]  will match if the MeSH phrase is contained within the authors name.
2018-04-01 10:08:49		If I were named Jesse Hemophilia, those mesh terms might still get caught on my name. 
2018-04-01 10:10:45	msbrown3	Well "Al-Gazali [MeSH Terms]" has 0 results 
2018-04-01 10:11:33	msbrown3	It seems like there just aren't any papers published on "Multiple epiphyseal dysplasia, Al-Gazali type". There is a parent disease "Multiple epiphyseal dysplasia" that has results though 
2018-04-01 10:12:23	msbrown3	some of the results are false positives for that, but there are some true positives also 
2018-04-01 10:13:24	msbrown3	I can make a script to duplicate pubmed connections for related diseases. I already did something similar with clinical trials 
2018-04-01 10:16:51	jesse	you might be able to add that function to one of my scripts. Check out the Pubmed_crawler directory in the scripts directory. 
2018-04-01 10:17:34	jesse	it may be easier than making a whole new script 
2018-04-01 10:18:25	msbrown3	It's a lot easier to do the tree-type queries in Django. 
2018-04-01 10:18:59	jesse	okay. 
2018-04-01 10:19:33	msbrown3	`disease.get_descendents()` and `disease.get_ancestors({'is_category': False})` 
2018-04-01 10:20:51	msbrown3	the script might take a long time though, with so many articles, but we'll see 
2018-04-01 10:21:41	jesse	I think it took around 2 hours to take out the duplicates. 
2018-04-01 10:22:01	msbrown3	ok, that's not so bad 
2018-04-01 10:22:03	msbrown3	Do you know why "Multiple epiphyseal dysplasia [MeSH Terms]" has so many false positive results? 
2018-04-01 10:22:44	jesse	I'll check it out now 
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 14:22:27		getting channel history...
2018-04-01 10:33:43	jesse	It's hard for me to tell if a result is a false positive since I don't really know what the disease is. Some of the results says things like 'Schwartz-Jampel Syndrome' or 'Melnick Needles' but if you look in the mesh terms on the pubmed site, they all are the same. 
2018-04-01 10:34:52	jesse	most of these that seem to be false positives are just different mesh phrases for the same disease. I'll keep looking for another false positive. 
2018-04-01 10:36:20	jesse	'Pericentrin: critical for spindle orientation' seems unrelated, but open the article up and it mentions osteodysplasty, which is part of another mesh term...  
2018-04-01 10:38:07	msbrown3	ok. Maybe it's something we can get Mike to look at sometime, but seems like it's ok 
2018-04-01 10:39:36	jesse	alright. 
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 10:13:45		getting channel history...
2018-04-01 10:47:12	msbrown3	thanks for looking into things. Sounds like it's going pretty well 
2018-04-01 10:49:32	jesse	no problem. I'm not too sure if it's going well or not. I probably should have gathered some statistics on how many of our diseases had mesh terms to search for and which ones just ran a simple text-based search. 
2018-04-01 10:51:03	jesse	Maybe i'll do that for the next time we have to run that script haha. we will no doubt have to run that script another dozen times xD 
2018-04-01 10:53:26	msbrown3	haha, yeah 
2018-04-03 17:42:09	jesse	i saw the issue you created about the duplicated articles.  I used to have it so that it would store a list of the queries diseases / disease ids, but Meaghan said it would be easier psql-wise to query the articles.
2018-04-03 17:42:09		i could probably make it more memory efficient by gathering all the articles, and make a new table that stores just which pmids match with which orpha ids, but that would take more psql logic.  let me know if you want me to do this. 
2018-04-03 17:43:05	msbrown3	it's probably something we should do later, but not worth it now 
2018-04-03 17:43:31	msbrown3	sortof created the issue so we don't forget about it, since we're not going to do it now 
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:34:27		getting channel history...
2018-04-03 17:43:51	jesse	now that im thinking about it, constructing the table would take a small script. the complicated thing would be the django end. 
2018-04-03 17:48:12	msbrown3	only if you have nothing else to do. It would be easy to query if the many-to-many table has foreign keys, but I haven't really seen pandas do that 
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-25 22:35:28	slackbot	Michael Brown has snoozed notifications. Send one anyway? slack-action://BSLACKBOT/dnd-override/297602664565/1524710128000245/298337926438/1524710128.000252 (Send notification)​​​ 
2018-04-28 10:28:13		getting channel history...
2018-04-03 18:55:11	jesse	well what I would do is just make a dataframe with only 2 columns: orpha id and pmid. once I have that, I can just de-duplicate the whole table removing the orpha id from the pubmed data.
2018-04-03 18:55:11		so, pandas wouldnt need to be able to do a many to many.... that would have to be done Django thing for the front end. 
2018-04-03 18:56:39	msbrown3	yea, except if it's not actually a foreign key, we have to manually query for all the IDs in Django instead of using all it's magic to make querying easy 
2018-04-03 19:04:51	jesse	couldnt we make the pmid the primary key? 
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:23		getting channel history...
2018-04-03 19:14:01	msbrown3	yes, but it wouldn't be a foreign key. We'd either have to make more complex queries in Django by selecting on IDs instead of using foreign keys, or write a script in django or sql to fill in the foreignkey fields 
2018-04-03 19:16:07	jesse	...sounds like we should wait on this problem :P 
2018-04-03 19:19:56	msbrown3	yeah 
2018-04-03 19:20:51	msbrown3	to be honest, it was an item on my whiteboard, and I put it in the issue tracker so I could erase it =P 
2018-04-03 19:39:39	jesse	xD i wanna white board... or rather, the super expensive paint that makes walls a whiteboard 
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:41:49		getting channel history...
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:43:27		getting channel history...
2018-04-05 13:12:12	msbrown3	https://www.rareconnect.org/
2018-04-05 13:12:12		RareConnect
2018-04-05 13:12:12		A safe, easy to use platform where rare disease patients, families and patient organizations can develop online communities and conversations across continents and languages. RareConnect partners with the world's leading rare disease patient groups to offer global online communities allowing people to connect around issues which affect them while living with a rare disease. 
2018-04-05 13:13:02	msbrown3	Also GHR might have some good links to organizations: https://ghr.nlm.nih.gov/condition/cln3-disease#resources
2018-04-05 13:13:02		CLN3 disease 
2018-04-08 13:01:13	jesse	Hey Michael, have you or Dr. Kowolenko already requested access to Orphanet's dataset? I was on this site: http://www.orphadata.org/cgi-bin/index.php/ but wasn't sure if someone else had already requested access. 
2018-04-08 13:01:13		OrphaData
2018-04-08 13:01:13		Provided by Orphanet 
2018-04-08 13:02:42	jesse	I was wanting their data on 'patient organizations'.  
2018-04-08 13:21:45	jesse	Also, do you know how http://ghr.nlm.nih.gov (ghr.nlm.nih.gov) is different from http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)? they seem to be roughly the same. 
2018-04-08 14:23:13	jesse	also, thought I replied to your earlier message. Rare Connect seems like it would be a good resource to link to under the resources tab. I could probably gather all of the links that points to each rare disease. it would just be a matter of comparing the names of the rare diseases to match our dataset. I think that would be more valuable than just saying the general info about the rareconnect forum.  
2018-04-09 07:58:43	msbrown3	Mike is talking with the Orphanet people. Hopefully we'll get that data soon 
2018-04-09 08:00:45	msbrown3	GHR has only genetics-related diseases. GARD (http://rarediseases.info.nih.gov (rarediseases.info.nih.gov)) has only rare diseases. Not sure why they overlap when they're both run by NIH. 
2018-04-09 08:02:06	msbrown3	yeah, that's what I was thinking for Rare Connect. We can normalize all of the names/synonyms and normalize the names of the communities on Rare Connect and see if any match 
2018-04-09 08:05:39	jesse	cool. A script should have finished giving us supporting organizations from NIH and NORD. I also gathered all the links from rare connect. from there it's pretty much just normalizing the names.
2018-04-09 08:05:39		I can look into gathering the support group info from GHR some time today or tomorrow. 
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:11:49		getting channel history...
2018-04-09 08:06:13	jesse	links as in hyperlinks... 
2018-04-09 08:09:08	jesse	sadly rare connect required selenium to webscrape 
2018-04-09 08:33:15	msbrown3	cool. Yeah, I noticed rare connect has a weird react framework site, basically everything rendered in js 
2018-04-09 08:35:42	jesse	yeah, it was kinda a pain. 
2018-04-09 08:35:51	jesse	lol 
2018-04-11 09:33:50	msbrown3	Hey. So I updated the specialists table, so I was trying to run your `getPhysicianPubmedConnection.py` script to update those connections 
2018-04-11 09:34:10	msbrown3	Do you remember how you created the `pubmed_authors_without_duplicates` table? 
2018-04-11 09:34:28	jesse	having problems with it? 
2018-04-11 09:34:50	msbrown3	yea, I just don't have that table 
2018-04-11 09:36:25	jesse	pubmed authors without duplicates is the same thing as pubmed authors. just rename the table in the python script.
2018-04-11 09:36:25		the way it generates the authors doesnt create any duplicates unless you have to halt and restart the program 
2018-04-11 09:36:56	jesse	when you are generating all the pubmed junk 
2018-04-11 09:37:45	jesse	I'm working on refactoring so that tweaks like that in my scripts are easier to spot. 
2018-04-11 09:38:02	jesse	(or nonexistant.) 
2018-04-11 09:39:54	msbrown3	ok. I just saw the scripts in the `duplicates/` folder, but looks like they're using some different tables I don't have also. But that's simple if I can just use the table I already have 
2018-04-11 09:40:44	jesse	Is there a way to import things in python using the project root directory? 
2018-04-11 09:40:52	msbrown3	so there's still multiple rows per author, it's just one per associated orpha_id, right? 
2018-04-11 09:40:59	jesse	yep 
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:09:35		getting channel history...
2018-04-11 09:41:05	msbrown3	yeah. I do it in most of my scripts, along with setting up the django stuff 
2018-04-11 09:41:37	jesse	do you have to be in the virtual environment for that to work? 
2018-04-11 09:42:21	msbrown3	no, doesn't have anything to do with virtualenv. but I think I had some of that stuff broken, since I usually run the scripts from the root project directory (like `python scripts/blah.py`) it just works 
2018-04-11 09:42:58	jesse	oh maybe the scripts folder is just missing __init__.py 
2018-04-11 09:43:30	msbrown3	that's only necessary if you're trying to `import scripts` 
2018-04-11 09:44:53	jesse	do you set your python path to the root directory of the project then?    
2018-04-11 09:45:24	msbrown3	yea, that's the idea. Like i said, some of my scripts might not be doing that right, but that's the idea 
2018-04-11 09:49:38	jesse	adding it to my python path solved the problem. I think that's automated on most systems cuz it seems like it's only a problem for me. It's not anything you did wrong though 
2018-04-11 09:53:53	jesse	as for my scripts though, the table names need to be updated. sometimes I'll append a '_2' to the end or something because the duplicates needs to be different from the original, and sometimes I check for duplicates and some times I don't because the program works fine start to finish 
2018-04-11 09:55:54	msbrown3	okay, good to know 
2018-04-11 10:02:55	jesse	I'm also planning on updating all of my scripts today and abstracting the common elements into the scripts/general folder. This should also make the process of making scripts quicker for me :) 
2018-04-11 10:04:18	jesse	progress bar is gonna be better too  
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-10 20:59:17		getting channel history...
2018-04-11 10:04:34	msbrown3	I'm about to make a few changes to `scripts/Pubmed_crawler/getPhysicianPubmedConnection.py` and `scripts/Pubmed_crawler/README.md` 
2018-04-11 10:05:01	jesse	that's fine I'll just be sure to pull and edit those last. 
2018-04-11 10:05:06	msbrown3	cool 
2018-04-11 10:12:40	msbrown3	ok, commited changes, including updating the table name to just use `pubmed_authors` 
2018-04-11 10:12:57	jesse	sounds good! 
2018-04-12 13:41:07	jesse	19310 Hemophilia articles. Want me to extend it past the limit of 100,000? Idk if anything will surpass it though. I can't just take it to the max, I have to manually determine a max. 
2018-04-12 13:53:24	jesse	I'll get you a max of 200,000 just to be safe. 
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/ 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 09:06:49		getting channel history...
2018-04-12 14:06:43	jesse	actually 200,000 would require me to reformat a decent bit of my code. I'll just run everything with 100,000 and we can see if anything hits the max. 
2018-04-13 08:09:59	msbrown3	yeah, tat sounds good for now 
2018-04-16 08:13:18	jesse	figured I should check in with ya about the pubmed articles stuff. the modified program has a bug in it that's pretty hard for me to fix, but it's related to the abstract classes I created to shorten the code rather than the limit change. 
2018-04-16 08:14:28	jesse	I'm gonna be looking more into it later, but for now, I'm just gonna focus on the alternative medicines. 
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-15 07:26:13		getting channel history...
2018-04-16 08:45:14	msbrown3	ok, that sounds good! 
2018-04-16 21:46:54	jesse	I'm getting nightmares michael. one website said it had a big database of alternative medicines.. it wasn't a database, it was a pdf of a table. Another website on alternative medicines called a CD of a Windows XP program, a database... lol  
2018-04-17 08:22:29	msbrown3	haha. that's scary. 
2018-04-17 08:59:54	jesse	it looks like the virtual machine ran out of memory... and I dont think its cuz of my stuff. also check for any other long scripts you guys may have been running at the same time within the past 12 hours. i was trying to do the pubmed stuff. 
2018-04-17 09:00:12	jesse	by memory, i mean disk space 
2018-04-17 09:22:26	msbrown3	on pubmed-jesse? I thought you and Sagar are the only ones on that machine. 
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-14 10:11:47	msbrown3	ok 
2018-05-14 10:12:27	msbrown3	postgres is probably a good idea, but probably either would work for development 
2018-05-15 10:41:23	jesse	hey something you might wanna check out:  https://docs.djangoproject.com/en/dev/howto/custom-management-commands/  
2018-05-15 10:41:35	jesse	we can make our own manage.py commands.  
2018-05-15 10:43:03	msbrown3	yeah, I'm actually working on a new data script framework that adds a "data" command 
2018-05-15 10:43:36	msbrown3	It's pretty easy to use actually 
2018-05-15 10:44:36	jesse	cool! I figured out how to make one of my scripts work like that with the pubmed stuff. so much easier than copying and pasting into a python/django terminal 
2018-05-15 10:45:05	msbrown3	awesome! that will be really nice 
2018-05-17 09:34:55		getting channel history...
2018-04-17 09:27:34	msbrown3	I free'd ~800mb on pubmed-jesse that I had from doing some debugging there yesterday 
2018-04-17 09:35:55	jesse	thanks. Ill look into it later. Charles schwab wants my picture lol.
2018-04-17 09:35:55		its possible that making the limit 100000 vastly increased the size of the table. 
2018-04-17 09:36:45	msbrown3	yea, your pubmed_articles table is 15GB 
2018-04-17 09:37:06	msbrown3	I'm assuming that's larger 
2018-04-17 09:37:25	jesse	xD, it only got to around 30% 
2018-04-17 09:37:34	msbrown3	O.o 
2018-04-17 11:54:08	jesse	sorry that was a typo, I meant to say 11% 
2018-04-17 11:55:39	jesse	I feel like this shouldn't be the case. I'm gonna play around with pubmed for a lil while and see if I can't get a real estimate for how many articles something has. 
2018-04-17 12:16:11	jesse	I think my program isn't clearing out the tables when I update the db. I think this is just a dumb mistake on my part 
2018-04-17 12:17:05	msbrown3	oh, that could be it. 
2018-04-17 12:17:44	msbrown3	I'm kindof hoping there are a lot of articles we weren't getting before, since we'll be able to make more specialist connections if we have more articles 
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-14 10:11:47	msbrown3	ok 
2018-05-14 10:12:27	msbrown3	postgres is probably a good idea, but probably either would work for development 
2018-05-15 10:41:23	jesse	hey something you might wanna check out:  https://docs.djangoproject.com/en/dev/howto/custom-management-commands/  
2018-05-15 10:41:35	jesse	we can make our own manage.py commands.  
2018-05-15 10:43:03	msbrown3	yeah, I'm actually working on a new data script framework that adds a "data" command 
2018-05-15 10:43:36	msbrown3	It's pretty easy to use actually 
2018-05-15 10:44:36	jesse	cool! I figured out how to make one of my scripts work like that with the pubmed stuff. so much easier than copying and pasting into a python/django terminal 
2018-05-15 10:45:05	msbrown3	awesome! that will be really nice 
2018-05-17 09:37:43	jesse	hey Michael, does it make sense for my pubmed downloader to be in 'disk sleep' state most of the time? 
2018-05-17 09:38:18	jesse	I assume that means it's doing IO, which makes sense. 
2018-05-17 09:39:34	msbrown3	hmm, I don't know 
2018-05-17 09:40:19	msbrown3	ahh, yea I think that's fine.  "While waiting for read() or write() to/from a file descriptor return, the process will be put in a special kind of sleep, known as "D" or "Disk Sleep"" 
2018-05-17 09:40:19	jesse	usually when it's put in the D state it jumps out immediately after. I'll try running the program locally and see if it behaves similarly 
2018-05-17 09:40:27	msbrown3	https://stackoverflow.com/questions/1475683/linux-process-states 
2018-05-17 09:43:07	jesse	ahh gotcha. 'Disk Sleep' made it sound like the hard drive was messed up haha. 
2018-05-17 09:43:14	msbrown3	yea, haha 
2018-05-17 09:58:52	jesse	should I call in again today for the meeting? 
2018-05-17 09:59:22	msbrown3	yeah. we're just moving into the conference room 
2018-05-17 09:59:37	msbrown3	we'll probably talk alot about the focus group that was on tuesday, and the upcoming one on Monday 
2018-05-21 08:18:48		getting channel history...
2018-04-17 12:21:44	jesse	yeah. I think that's only going to be the case with the popular rare diseases though. many of the pubmed searches don't return very many results. 
2018-04-17 12:29:26	jesse	we'll see. I think this time the script will run all the way through xD 
2018-04-17 12:29:45	msbrown3	cool 
2018-04-17 12:29:54	msbrown3	yeah, I guess there's not much we can do about the super rare diseases 
2018-04-17 12:32:07	jesse	i love that we're at the point where we need to subcategorize rare diseases as popular and super rare lol. 
2018-04-17 12:37:10	msbrown3	haha, yeah 
2018-04-17 12:37:44	msbrown3	it's crazy that there's some that come up with like no results when you search places though 
2018-04-17 12:39:11	jesse	yeah. do you remember off hand what percentage of diseases have symptoms in our data?  
2018-04-17 12:40:31	msbrown3	4788 / 7721 have no phenotypes 
2018-04-17 12:40:56	msbrown3	so 2933 / 7721 have them 
2018-04-17 12:42:18	msbrown3	we're trying to make it so diseases that don't have phenotypes will get them by parent/child diseases. I think the main reason why so many don't have phenotypes is that subtypes don't always have phenotypes. Like CLN3 doesn't, but JCLN does 
2018-04-17 12:43:33	jesse	thats not a terrible amount. With the alternative medicines, I won't be able to take a rare disease name and point someone to treatments, but I might be able to link the symptoms to herbal remedies to treat the symptoms. The issue with that is that the herbal remedies community does not use medical terms with their symptoms, so that's going to make my life difficult.  
2018-04-17 12:45:44	jesse	Aside from herbal remedies, everything else seems to be an 'All in one cure' kind of deal... so things like acupuncture, yoga, chiropractors, or whatever aren't things that I can link to, but I might be able to find sources to get 'chiros in your area' kind of thing 
2018-04-17 12:46:30	jesse	I 
2018-04-17 12:47:06	jesse	I'm not sure if that's what Kowolenko was wanting though. Hey may have thought that there would be some super database that would have everything... 
2018-04-17 12:48:21	msbrown3	yea. I don't think it makes sense to link to things that aren't related enough to the disease, at least most of the time 
2018-04-17 12:48:43	msbrown3	but at least herbal remedies has some symptom related info? 
2018-04-17 12:50:44	jesse	I can give you an example: https://www.drugs.com/npp/acai.html
2018-04-17 12:50:44		Acai Uses, Benefits & Dosage - Drugs.com Herbal Database
2018-04-17 12:50:44		Learn about the potential benefits of Acai including contraindications, adverse reactions, toxicology, pharmacology and historical usage. 
2018-04-17 12:51:58	jesse	They will use terms like anti-oxidant, anti-inflammatory or pain/flu rather than the symptom's doctor terminology. 
2018-04-17 12:52:04	jesse	another example is : http://www.holisticonline.com/Herbal-Med/_Herbs/h9.htm
2018-04-17 12:52:04		herb data, American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American, holisticonline.com
2018-04-17 12:52:04		Herbal medicine. herb data for American Ginseng, Panax Ginseng, Panax quinquefolius, Five fingers, Tartar Root, five leafed ginseng, redberry, garantoquen, sang, Ginseng - American 
2018-04-17 12:53:05	jesse	it'll call it a stomachic or panacea, but that doesn't give us Ahem  "specificity and context" 
2018-04-17 12:55:25	msbrown3	hmm, yeah that seems hard to match up 
2018-04-17 12:56:45	jesse	yeah. I'm not really sure how to approach that one. Maybe arun will find something else. 
2018-04-17 12:59:24	jesse	If we don't need specific information on chiropractors, yoga gurus, or other things like that, we could probably just embed a google maps search for those sorts of things... if that information is valuable. 
2018-04-17 13:07:57	msbrown3	yeah, wouldn't be hard to link to google maps. 
2018-04-17 13:08:39	msbrown3	not sure it's that valuable, but if that's the best we can do then we can talk about in a meeting 
2018-04-17 13:10:53	jesse	Ok. Arun says hes gonna be searching for stuff later tonight/tomorrow, so I'm gonna check in with him and keep you guys posted. 
2018-04-17 13:12:21	msbrown3	ok, sounds good! 
2018-04-21 10:27:37	jesse	Do you know how to take a process that is sleeping and make i t run again?  the pubmed crawler stopped at 54% and has been a sleeping process for at least a day.. maybe 2 
2018-04-21 10:28:37	msbrown3	sleeping in what way? Did you accidently press CTRL-Z in the terminal? 
2018-04-21 10:30:13	jesse	@jesse uploaded a file: https://ncstateuniversityitng.slack.com/files/U8QQFV2GG/FAASFEYRG/screenshot.png (screenshot) 
2018-04-21 10:31:08	jesse	the S column stands for 'State' and the S under the State column stands for Sleeping. Based on the elapsed times, it's been sleeping for quite a long time. 
2018-04-21 10:32:08	jesse	This could be for a number of different reasons... since this is a VM, there could be another process on the same server that's taking up processing time. or maybe the OS thinks that task is worthless.. 
2018-04-21 10:33:27	msbrown3	that seems unlikely. it's getting zero cpu time 
2018-04-21 10:34:02	msbrown3	I could debug it with gdb, see where it is in the code 
2018-04-21 10:34:23	jesse	you can gdb a running process? 
2018-04-21 10:35:09	msbrown3	yeah 
2018-04-21 10:35:56	msbrown3	`gdb python -p 423` I think 
2018-04-21 10:37:23	jesse	list 
2018-04-21 10:37:29	jesse	woops... wrong terminal 
2018-04-21 10:37:34	msbrown3	haha 
2018-04-21 10:40:32	jesse	its in a sqlalchemy line, but I'm not getting much useful info out of it. 
2018-04-21 10:40:40	msbrown3	btw, `detach` is the how you get out of gdb and keep the process runing 
2018-04-21 10:41:17	jesse	its not even pointing to a place in my code. 
2018-04-21 10:41:43	msbrown3	What happens if you `step` or `next`? 
2018-04-21 10:42:08	msbrown3	as in, is it stuck on one line of code, or is it going in a loop 
2018-04-21 10:44:50	jesse	step:   single stepping until exit from function read, which has no line number information 
2018-04-21 10:48:46	jesse	now the gdb process is asleep... 
2018-04-21 10:49:01	jesse	lol 
2018-04-21 10:49:42	msbrown3	yea, so it's stuck on some sleep or i/o statement 
2018-04-21 10:50:34	msbrown3	you can CTRL-C to get back to gdb 
2018-04-21 10:51:12	msbrown3	so where is it in the code exactlly? (output of `bt` command) 
2018-04-21 10:51:39	msbrown3	there's some way to get gdb to recognize python data structures, but I don't remember how 
2018-04-21 10:52:31	jesse	yeah there was some debug-install function gdb was recommending to me, but then my shell wouldn't recognize that command. 
2018-04-21 10:56:09	msbrown3	This might help get better debug info from python: https://devguide.python.org/gdb/ 
2018-04-21 10:56:28	msbrown3	or maybe ipdb can attach to a running process? 
2018-04-21 10:57:23	jesse	im getting code now :P 
2018-04-21 10:58:33	jesse	i may have spoken too soon... its all in C lol 
2018-04-21 11:07:47	msbrown3	so it's stuck in sqlachemy, isn't that only used in the step of saving data to postgres? 
2018-04-21 11:07:59	jesse	yeah. 
2018-04-21 11:13:35	msbrown3	might be some kind of postgres locking thing? 
2018-04-21 11:14:29	jesse	idk. I can't imagine that being an issue. nothing else is touching the db. 
2018-04-21 11:16:21	msbrown3	I'm guessing it's waiting to hear back from postgres. There's a postgres process `postgres   429  0.0  0.0 236168  5240 ?        Ss   Apr18   0:00 postgres: jlsimps4 raredx [local] idle in transaction` that seems to be trying to handle a request but isn't doing anything 
2018-04-21 11:17:34	msbrown3	That process (pid 429) has some locks, just not sure what it means yet 
2018-04-21 11:17:38	msbrown3	```
2018-04-21 11:17:38		postgres=# select * from pg_locks;
2018-04-21 11:17:38		  locktype  | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction | pid  |      mode       | granted | fastpath 
2018-04-21 11:17:38		------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+------+-----------------+---------+----------
2018-04-21 11:17:38		 relation   |    12924 |    11069 |      |       |            |               |         |       |          | 6/445507           | 1515 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 6/445507   |               |         |       |          | 6/445507           | 1515 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		 relation   |    16385 |    32560 |      |       |            |               |         |       |          | 3/185              |  429 | AccessShareLock | t       | t
2018-04-21 11:17:38		 virtualxid |          |          |      |       | 3/185      |               |         |       |          | 3/185              |  429 | ExclusiveLock   | t       | t
2018-04-21 11:17:38		(4 rows)
2018-04-21 11:17:38		```  (edited)
2018-04-21 11:18:33	jesse	So you think it just got deadlocked? 
2018-04-21 11:20:31	msbrown3	Seems weird, but that's my guess. It is a really old version of postgres, no longer supported 
2018-04-21 11:21:25	msbrown3	9.2 was released in 2012. Support ended in 2017 
2018-04-21 11:21:59	jesse	xD wasn't there a reason we were sticking with the old version? 
2018-04-21 11:22:10	msbrown3	maybe not a locking thing, since the table actually says the locks were granted 
2018-04-21 11:22:19	jesse	maybe I'm thinking of elasticsearch 
2018-04-21 11:23:22	msbrown3	Not sure why the version is so old.... it is CentOS7 which has pretty old software to begin with, but I think the instructions we had been using to install postgres were just copied from project to project until it got out of date 
2018-04-21 11:24:13	jesse	Is there a way to update postgres without the contents of the db being affected? 
2018-04-21 11:29:47	msbrown3	probably? 
2018-04-21 11:30:13	jesse	xD I'll look into it. 
2018-04-21 11:30:52	msbrown3	if there's enough space, you can make a dump of the database, then run postgres9.6 and restore it there 
2018-04-21 11:31:20	msbrown3	pubmed-jesse has postgres 9.6 btw, it's just not running 
2018-04-21 11:31:23	jesse	thats questionable 
2018-04-21 11:31:53	msbrown3	the space issue is questionable, or the method? 
2018-04-21 11:32:37	jesse	space. Im currently at 52% so we would just barely have enough 
2018-04-21 11:33:13	msbrown3	maybe we can get it onto another drive 
2018-04-21 11:34:12	msbrown3	there's also pg_upgrade, not sure how it works though 
2018-04-21 11:34:13	msbrown3	https://www.postgresql.org/docs/9.6/static/pgupgrade.html 
2018-04-21 11:36:01	msbrown3	for now you can just try restarting postgres and running the crawler again 
2018-04-21 11:36:37	jesse	thats not a very good option... this has happened a few times before. 
2018-04-21 11:36:42	msbrown3	oh, ok 
2018-04-21 11:37:11	msbrown3	do you need the data in the 9.2 instance now? 
2018-04-21 11:38:00	jesse	i mean, Id prefer if we didnt have to regenerate all of the 52% of information again. 
2018-04-21 11:42:31	msbrown3	pg_upgrade seems like the way to go. I can give it a shot if you want 
2018-04-21 11:42:46	jesse	yeah I've been trying, but it seems like I don't have that command 
2018-04-21 11:46:44	msbrown3	ok, I'm going to stop postgres 
2018-04-21 11:46:57	jesse	ok 
2018-04-21 11:47:04	jesse	dont fall asleep 
2018-04-21 12:08:26	msbrown3	....i didn't, just working on it =P 
2018-04-21 12:10:19	jesse	(cuz all the processes that touched my crawler fell asleep).. so turns out, the process couldn't have stopped when it was writing to the db, cuz it only writes to the db on intervals of 50 diseases at a time... and it stopped on 3986.   
2018-04-21 12:11:50	jesse	which doesn't make any sense lol. unless some python garbage collector took away the postgres connector/engine. 
2018-04-21 12:13:48	msbrown3	doesn't that mean it has to have stopped in the middle of a write? 
2018-04-21 12:15:28	jesse	nope. I just created one or two connectors that works for the entire script. If some garbage collector thought it was useless, then it could have been thrown out at any time.  but that seems unlikely. 
2018-04-21 12:16:03	jesse	And that is within another python object rather than explicitly defined. 
2018-04-21 12:16:36	msbrown3	I'm not sure if we can easily do this upgrade with pg_upgrade. Problem is postgis. Postgres 9.2 and 9.6 have a different version of postgis 
2018-04-21 12:18:13	jesse	in that case, lets just tear everything down, upgrade to 9.6, and regenerate everything. We won't know if that will fix the random sleeping states, but I guess we'll be closer to fixing it. 
2018-04-21 12:19:02	msbrown3	yeah. we can backup the 9.2 data in case, and possibly even do a restore from it 
2018-04-21 12:21:03	msbrown3	Well, like I said, both are already installed. You can start/stop/etc 9.6 using systemctl: `sudo systemctl status postgresql-9.6` 
2018-04-21 12:23:35	jesse	gotcha. 
2018-04-21 12:24:28	jesse	are you doing that or should I? 
2018-04-21 12:27:12	msbrown3	I have to head out soon, so why don't you do it 
2018-04-21 12:27:32	jesse	sounds good 
2018-04-21 12:27:46	msbrown3	feel free to ask questions, but I might be away for the afternoon 
2018-04-21 12:29:33	jesse	that's fine. I probably won't do too much raredx stuff this weekend. just homework, and then I'll come in during the week. 
2018-04-21 12:30:21	msbrown3	cool, sounds good 
2018-04-21 13:10:15	jesse	alright. the new db is updated and contains all the old info.. sagar, janne, and arun don't have roles on this, but I don't really see that as much of a problem since they weren't using it anyway :P 
2018-04-23 17:13:23	jesse	for whatever reason, dropping the abstract column doesn't seem to be freeing up disk space. do you know why that would be? 
2018-04-23 18:13:41	msbrown3	Maybe it doesn't actually delete that data, since that would require rewriting the whole table 
2018-04-23 18:14:38	jesse	that might be the case. maybe if I did a pgdump and re-uploaded the database, it would free up the space. 
2018-04-23 18:15:22	jesse	or maybe it would just stay the same size... being a true copy. 
2018-04-23 18:19:06	msbrown3	that might work, if you drop the table the restore it from a dump 
2018-04-24 11:02:54	jesse	Hey Michael, what was the disease you searched that got more than 10,000 entries? 
2018-04-24 11:03:34	msbrown3	Hemophilia is one 
2018-04-24 11:06:48	jesse	That one has 19,000 results. I'm trying to find others to see if I can are getting close to that 100,000 limit. 
2018-04-24 11:06:56	jesse	I'm probably good though. 
2018-04-24 11:07:39	msbrown3	yeah, probably 
2018-04-24 11:07:53	msbrown3	Hopefully it makes more specialist connections 
2018-04-24 11:09:38	jesse	oh good point. I should probably run that script haha. 
2018-04-25 22:35:28	jesse	we have almost twice as many pubmed specialist connections. 20,000 -> 38,000 
2018-04-26 07:19:16	msbrown3	wow, nice! 
2018-04-28 13:08:08	jesse	completely hypothetically speaking... is it okay to recommend a 'scorpion' for hearing impairment? 
2018-04-28 13:49:04	jesse	aside from the scorpion, the data seems pretty good. And things are matching up a lot better than I had expected. I was thinking I was gonna have to map the symptom to an organ system then the organ system to the herbal remedy. I might still do that, but we are getting enough results as is. It's more of a matter of whether you guys think these results are good or not. or if there are other data sources we should look at. 
2018-04-30 10:28:15	msbrown3	that's hilarious. Something makes me think that's not hypothetical 
2018-04-30 10:29:49	jesse	xD I looked it up. Chinese people do eat scorpions for medicinal purposes. Apparently they're rich in nutrients.  
2018-04-30 10:30:17	msbrown3	cool 
2018-04-30 10:38:56	msbrown3	wonder if that actually works 
2018-04-30 10:42:50	jesse	I wanna try it. 
2018-04-30 10:43:27	msbrown3	haha, go for it. 
2018-04-30 15:44:19	jesse	Hey Michael, is there a way I can make a list of all of the phenotypes that aren't listed under any disease? 
2018-04-30 15:44:38	msbrown3	yes 
2018-04-30 15:44:55	msbrown3	I can do that in Django pretty quick 
2018-04-30 15:46:49	jesse	could you do that for me please? or tell me where in models I need to look? 
2018-04-30 15:47:56	jesse	i guess diseasephenotype would have that info. 
2018-04-30 15:49:23	msbrown3	`models.Phenotype.objects.filter(diseasephenotype=None)` 
2018-04-30 15:49:46	jesse	THANKS!!!!! 
2018-04-30 15:50:22	msbrown3	np 
2018-04-30 15:50:56	msbrown3	there are a lot more phenotypes without diseases than phenotypes with diseases. You can do `models.Phenotype.objects.filter(diseasephenotype__isnull=False)` for phenotypes with diseases 
2018-04-30 15:56:07	jesse	Yeah. I noticed that there were some oddly specific and awfully medically termed phenotypes that are in there so matching those ones up to herbal remedies doesn't seem very worthwhile. I'm thinking we should only try to match the common things like 'nausea, vomitting, weight loss' rather than 'Abnormality of Mandibular Symphysis'... whatever that means lol.  
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-14 10:11:47	msbrown3	ok 
2018-05-14 10:12:27	msbrown3	postgres is probably a good idea, but probably either would work for development 
2018-05-15 10:41:23	jesse	hey something you might wanna check out:  https://docs.djangoproject.com/en/dev/howto/custom-management-commands/  
2018-05-15 10:41:35	jesse	we can make our own manage.py commands.  
2018-05-15 10:43:03	msbrown3	yeah, I'm actually working on a new data script framework that adds a "data" command 
2018-05-15 10:43:36	msbrown3	It's pretty easy to use actually 
2018-05-15 10:44:36	jesse	cool! I figured out how to make one of my scripts work like that with the pubmed stuff. so much easier than copying and pasting into a python/django terminal 
2018-05-15 10:45:05	msbrown3	awesome! that will be really nice 
2018-05-17 09:37:43	jesse	hey Michael, does it make sense for my pubmed downloader to be in 'disk sleep' state most of the time? 
2018-05-17 09:38:18	jesse	I assume that means it's doing IO, which makes sense. 
2018-05-17 09:39:34	msbrown3	hmm, I don't know 
2018-05-17 09:40:19	msbrown3	ahh, yea I think that's fine.  "While waiting for read() or write() to/from a file descriptor return, the process will be put in a special kind of sleep, known as "D" or "Disk Sleep"" 
2018-05-17 09:40:19	jesse	usually when it's put in the D state it jumps out immediately after. I'll try running the program locally and see if it behaves similarly 
2018-05-17 09:40:27	msbrown3	https://stackoverflow.com/questions/1475683/linux-process-states
2018-05-17 09:40:27		Linux Process States
2018-05-17 09:40:27		In Linux, what happens to the state of a process when it needs to read blocks from a disk? Is it blocked? If so, how is another process chosen to execute? 
2018-05-17 09:43:07	jesse	ahh gotcha. 'Disk Sleep' made it sound like the hard drive was messed up haha. 
2018-05-17 09:43:14	msbrown3	yea, haha 
2018-05-17 09:58:52	jesse	should I call in again today for the meeting? 
2018-05-17 09:59:22	msbrown3	yeah. we're just moving into the conference room 
2018-05-17 09:59:37	msbrown3	we'll probably talk alot about the focus group that was on tuesday, and the upcoming one on Monday 
2018-05-21 08:28:12	jesse	Hey Michael, to let you know where I'm at, the baseline program is stable, and has been running for 9 hours now, but it's only managed to read 1 of the 927 files during that time. the progress bar estimates that it will complete in 149 days. I'm thinking about ways to speed it up but we may lose the connection between authors and articles,  as well as articles and mesh headings. 
2018-05-21 08:29:43	jesse	I'm thinking about making a giant list of article objects and then bulk saving them into the database, cuz I think most of the time is being lost through context switches. 
2018-05-21 09:46:06	msbrown3	yeah, the bulk save is a good idea. In my experience the number of database calls is what makes these data scripts so slow 
2018-05-21 09:48:22	jesse	the only issue with that is that using many to many fields require both objects to be in the database first. 
2018-05-21 09:48:59	jesse	so I'm probably just gonna try storing the ids. 
2018-05-21 09:49:31	msbrown3	Is the authors table small enough you can store that in memory until the end? 
2018-05-21 09:52:45	jesse	I doubt it. but im not sure. 
2018-05-21 10:48:01	jesse	new time estimate is about 5 days. I'm not sure what to do about how to relate the pubmed articles to the authors or the headings. right now, the authors and the headings just have a pmid field that points it to the article but not the other way around because I wouldn't know what the id field of the authors or the headings is, since they are auto-generated. 
2018-05-21 10:48:56	jesse	authors and mesh headings will also contain a lot of duplicated info, since I'm doing bulk inserts rather than a update_or_create kind of thing. 
2018-05-21 10:51:18	msbrown3	ok. that sounds fine for now. I don't imagine having duplicate authors will take up that much space compared to the pubmed articles themselves 
2018-05-21 10:52:16	jesse	alright. I agree. I'll try to do something about the daily updates for the time being. 
2018-05-21 10:52:29	msbrown3	ok cool 
2018-05-21 10:52:41	msbrown3	thanks for the update 
2018-05-21 11:44:15	jesse	I wrote the script for the daily updates but I will need all the pubmed articles in to test it. Everythings pushed if you wanted to take a look and see if you can spot bugs, but aside from that and waiting for the main script to finish, I should be free to work on something else. 
2018-05-21 11:44:56	jesse	Also, I don't think those update files include removing articles, so I didn't account for it. 
2018-05-21 13:40:29	msbrown3	do they have any mechanism for removing articles? 
2018-05-21 13:41:21	jesse	it didnt look like it. I could have missed it though. it looked like the same format as the baseline stuff. 
2018-07-28 12:22:51		getting channel history...
2018-04-30 16:21:40	jesse	Michael, I'm encountering something odd.. 
2018-04-30 16:21:56	jesse	In [14]: len(models.Phenotype.objects.filter(diseasephenotype__isnull=False)) 
2018-04-30 16:21:56	jesse	Out[14]: 64182 
2018-04-30 16:22:11	jesse	In [11]: len(models.Phenotype.objects.all()) 
2018-04-30 16:22:11	jesse	Out[11]: 13431 
2018-04-30 16:22:20	jesse	is it just me or does this make no sense? 
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-14 10:11:47	msbrown3	ok 
2018-05-14 10:12:27	msbrown3	postgres is probably a good idea, but probably either would work for development 
2018-05-15 10:41:23	jesse	hey something you might wanna check out:  https://docs.djangoproject.com/en/dev/howto/custom-management-commands/  
2018-05-15 10:41:35	jesse	we can make our own manage.py commands.  
2018-05-15 10:43:03	msbrown3	yeah, I'm actually working on a new data script framework that adds a "data" command 
2018-05-15 10:43:36	msbrown3	It's pretty easy to use actually 
2018-05-15 10:44:36	jesse	cool! I figured out how to make one of my scripts work like that with the pubmed stuff. so much easier than copying and pasting into a python/django terminal 
2018-05-15 10:45:05	msbrown3	awesome! that will be really nice 
2018-05-17 09:37:43	jesse	hey Michael, does it make sense for my pubmed downloader to be in 'disk sleep' state most of the time? 
2018-05-17 09:38:18	jesse	I assume that means it's doing IO, which makes sense. 
2018-05-17 09:39:34	msbrown3	hmm, I don't know 
2018-05-17 09:40:19	msbrown3	ahh, yea I think that's fine.  "While waiting for read() or write() to/from a file descriptor return, the process will be put in a special kind of sleep, known as "D" or "Disk Sleep"" 
2018-05-17 09:40:19	jesse	usually when it's put in the D state it jumps out immediately after. I'll try running the program locally and see if it behaves similarly 
2018-05-17 09:40:27	msbrown3	https://stackoverflow.com/questions/1475683/linux-process-states
2018-05-17 09:40:27		Linux Process States
2018-05-17 09:40:27		In Linux, what happens to the state of a process when it needs to read blocks from a disk? Is it blocked? If so, how is another process chosen to execute? 
2018-05-17 09:43:07	jesse	ahh gotcha. 'Disk Sleep' made it sound like the hard drive was messed up haha. 
2018-05-17 09:43:14	msbrown3	yea, haha 
2018-05-17 09:58:52	jesse	should I call in again today for the meeting? 
2018-05-17 09:59:22	msbrown3	yeah. we're just moving into the conference room 
2018-05-17 09:59:37	msbrown3	we'll probably talk alot about the focus group that was on tuesday, and the upcoming one on Monday 
2018-05-21 08:28:12	jesse	Hey Michael, to let you know where I'm at, the baseline program is stable, and has been running for 9 hours now, but it's only managed to read 1 of the 927 files during that time. the progress bar estimates that it will complete in 149 days. I'm thinking about ways to speed it up but we may lose the connection between authors and articles,  as well as articles and mesh headings. 
2018-05-21 08:29:43	jesse	I'm thinking about making a giant list of article objects and then bulk saving them into the database, cuz I think most of the time is being lost through context switches. 
2018-05-21 09:46:06	msbrown3	yeah, the bulk save is a good idea. In my experience the number of database calls is what makes these data scripts so slow 
2018-05-21 09:48:22	jesse	the only issue with that is that using many to many fields require both objects to be in the database first. 
2018-05-21 09:48:59	jesse	so I'm probably just gonna try storing the ids. 
2018-05-21 09:49:31	msbrown3	Is the authors table small enough you can store that in memory until the end? 
2018-05-21 09:52:45	jesse	I doubt it. but im not sure. 
2018-05-21 10:48:01	jesse	new time estimate is about 5 days. I'm not sure what to do about how to relate the pubmed articles to the authors or the headings. right now, the authors and the headings just have a pmid field that points it to the article but not the other way around because I wouldn't know what the id field of the authors or the headings is, since they are auto-generated. 
2018-05-21 10:48:56	jesse	authors and mesh headings will also contain a lot of duplicated info, since I'm doing bulk inserts rather than a update_or_create kind of thing. 
2018-05-21 10:51:18	msbrown3	ok. that sounds fine for now. I don't imagine having duplicate authors will take up that much space compared to the pubmed articles themselves 
2018-05-21 10:52:16	jesse	alright. I agree. I'll try to do something about the daily updates for the time being. 
2018-05-21 10:52:29	msbrown3	ok cool 
2018-05-21 10:52:41	msbrown3	thanks for the update 
2018-05-21 11:44:15	jesse	I wrote the script for the daily updates but I will need all the pubmed articles in to test it. Everythings pushed if you wanted to take a look and see if you can spot bugs, but aside from that and waiting for the main script to finish, I should be free to work on something else. 
2018-05-21 11:44:56	jesse	Also, I don't think those update files include removing articles, so I didn't account for it. 
2018-05-21 13:40:29	msbrown3	do they have any mechanism for removing articles? 
2018-05-21 13:41:21	jesse	it didnt look like it. I could have missed it though. it looked like the same format as the baseline stuff. 
2018-05-21 13:43:19	msbrown3	hmm, okay 
2018-05-21 13:48:32	jesse	ill double check later to be sure 
2018-05-29 09:55:56	msbrown3	Hey Jesse. I noticed the rareconnect communities runs really slow. Do you think you have time to make it faster by tomorrow night for the production push? 
2018-05-29 10:07:34	jesse	ahh really? i thought it was running fine when I checked. I'll do something about it 
2018-05-29 10:11:56	msbrown3	cool, thanks 
2018-05-29 10:26:10	jesse	i was running it on my desktop :P 
2018-05-29 10:26:10		maybe thats why it was quick for me. 
2018-05-29 10:28:12	msbrown3	hmm yeah. I wounder if production is faster than my VM 
2018-05-29 14:12:02	jesse	hey michael, does disease.get_family include the disease itself? 
2018-05-29 14:12:37	jesse	I think it does based on the code in disease.py but i wanted to double check. 
2018-05-29 14:13:41	jesse	nvm it does. 
2018-05-29 14:14:00	msbrown3	yeah 
2018-05-29 14:16:27	jesse	one more thing: how do you typically run django scripts? 
2018-05-29 14:17:10	jesse	putting it in management/commands works well for me, but before that, I was just copying and pasting code into the django shell... and that didnt work well. 
2018-05-29 14:18:06	jesse	all of our scripts being in a scripts directory makes that a bit difficult unless I copy the scripts I need over into management/commands. 
2018-05-29 14:19:39	msbrown3	`python scripts/foo.py` 
2018-05-29 14:20:33	msbrown3	I've been working on a script framework for rarediseases, so it's moving to useage like this: `./manage.py data run OrphaDisease` 
2018-05-29 14:20:33	jesse	does that work if you are messing with Disease.objects.blah? 
2018-05-29 14:23:13	msbrown3	yes if you put some stuff at the beginning that initializes django 
2018-05-29 14:23:38	jesse	ahh. That must be what I've been missing. 
2018-05-29 14:24:24	msbrown3	```python
2018-05-29 14:24:24		import django
2018-05-29 14:24:24		os.environ.setdefault("DJANGO_SETTINGS_MODULE", "project.settings")
2018-05-29 14:24:24		django.setup()
2018-05-29 14:24:24		``` 
2018-05-29 14:25:35	msbrown3	uhh, can't edit that for some reason, but "python" shouldn't be in the first line 
2018-05-29 14:26:03	jesse	i gotcha.  
2018-05-29 14:57:03	jesse	I just screwed up django...  
2018-05-29 14:57:11	jesse	xD nothing is working now 
2018-05-29 15:11:26	msbrown3	O.o 
2018-05-29 15:11:29	msbrown3	what's happening? 
2018-05-29 15:12:06	jesse	nothing. any process going through manage.py just hangs. 
2018-05-29 15:12:35	jesse	i'm going through the setup process again now 
2018-05-29 15:12:48	msbrown3	for pubmed or rarediseases? 
2018-05-29 15:14:35	msbrown3	you could try using the debugger: `pip install ipdb; python -m ipdb manage.py` 
2018-05-29 15:14:41	msbrown3	to see where it's hanging 
2018-05-29 15:15:14	jesse	rarediseases. and thanks. I'll give that a try. 
2018-05-29 15:24:50	jesse	it somehow was related to pycache... removing it fixed the issue 
2018-05-29 15:29:22	msbrown3	weird 
2018-05-29 17:26:55	jesse	do you know why django isn't creating the tables when I add something into models/ makemigrations/ migrate? 
2018-05-30 08:19:40	msbrown3	are you using `--database data` when mirgating? 
2018-05-30 08:20:43	jesse	i think I tried it, but it didnt do anything. 
2018-05-30 08:23:42	msbrown3	hmm. does the migration file actually have a create table operation in it? 
2018-05-30 08:36:57	jesse	I'll check in a moment. I'm not at my computer rn 
2018-05-30 08:53:01	jesse	it does not. it has create model operations in it though. I kinda think it's because I'm using old data. 
2018-05-30 08:55:02	jesse	wait... --database data may have fixed it... I thought I tried that.  
2018-05-30 08:55:30	msbrown3	oh cool 
2018-05-30 08:55:46	msbrown3	the create model operation should create the table in the database 
2018-05-30 09:02:47	jesse	actually i was wrong... I forgot I tried making a table in the db last night.. my program had an issue with the auto id field which is why i wanted django to make the table for me. 
2018-05-30 09:10:01	jesse	ok. so I got the tables to generate for every other table other than the one I created. am I supposed to do something other than add the Model to the models folder? 
2018-05-30 09:10:42	msbrown3	oh, you should import it in rarediseases/models/__init__.py 
2018-05-30 09:11:21	jesse	yeah i did that :( 
2018-05-30 09:11:34	msbrown3	:disappointed: 
2018-05-30 09:16:49	jesse	got it! i made it generate in a separate db and I pg_dumped it into mine :P 
2018-05-30 09:19:41	jesse	One more thing:  the program runs very slowly making all of the comparisons. I'm thinking some of the diseases families might be very big which means I'm doing a lot more comparisons than i need. Do you think I should limit it to only compare 5 branches in it's family path? 
2018-05-30 10:04:12	msbrown3	how slowly does it run? Can you speed it up by making an index dictionary for the community names or something? 
2018-05-30 10:06:58	jesse	it took about 10 minutes to go through the disease at index 6. which means it would take 10 minutes for any disease within object 6ths family graph. and there is 10,000 objects 
2018-05-30 10:07:07	jesse	total. 
2018-05-30 10:08:41	jesse	but I am going through each disease and comparing every rareconnect link with  each of them. 
2018-05-30 10:10:42	jesse	also, it seems like steel syndrome is showing results for eec syndrome, ehlers danlos syndrome, nephrotic syndrome and some others that im not sure are related 
2018-05-30 10:14:23	msbrown3	hmm... is the disease family thing not doing what you want? 
2018-05-30 10:14:39	msbrown3	also, the disease family query is kindof expensive in itself 
2018-05-30 10:19:15	jesse	it is very expensive. the script runs 10 seconds without checking the family, but going one family member deep makes the scripts ETA hours... It seems to be doing what I want, but I think I'm misunderstanding how big these trees are. it might give us misleading results if we check all of them.  
2018-05-30 10:20:10	msbrown3	I think some of the families are big, but shouldn't be that many of them 
2018-05-30 10:20:20	msbrown3	that is, most should be small 
2018-05-30 10:21:59	jesse	I'll spend some more time trying to make it more efficient and see where it takes me.  
2018-05-30 10:22:48	msbrown3	ok 
2018-05-30 11:36:55	jesse	I found a way to make it a bit more efficient, but the biggest issue that is taking the processing time is checking every family member. There were 2 diseases that I saw with family members over 900 family members... which means that there are 900 diseases each with at least 900 family members making for 810,000 comparisons. and I found 2 of those.  I'll try to run it without limitting the families and get an estimate for how long the script will run.  
2018-05-30 11:37:46	jesse	right now, it might be 8-24 hours. 
2018-05-30 11:38:18	msbrown3	wow, why are there 900? 
2018-05-30 11:40:21	msbrown3	can you give me an example disease? 
2018-05-30 11:40:24	jesse	i dunno. the id was 39084. id_orpha=183763 if you wanna check it out. 
2018-05-30 11:40:33	msbrown3	yeah 
2018-05-30 11:41:25	jesse	Rare genetic syndromic intellectual disability is the name... which seems very vague 
2018-05-30 11:41:36	msbrown3	yeah... it's a category 
2018-05-30 11:42:06	msbrown3	ohhhh, and it has 387 children, each of which probably have a few subtypes 
2018-05-30 11:42:36	jesse	I filtered the diseases to not include categories, but that kind of code isn't included in the get_family() function 
2018-05-30 11:44:33	jesse	as in get_family will return categories or parents/children of categories. 
2018-05-30 11:44:34	msbrown3	all of a disease's family should have is_category=False, it filters for that 
2018-05-30 11:44:55	jesse	okay. thats good. 
2018-05-30 11:45:50	msbrown3	but you're calling get_family() on a category? 
2018-05-30 11:47:43	jesse	nah I removed that problem :) 
2018-05-30 11:47:58	jesse	in my test program i was though 
2018-05-30 11:48:05	jesse	not my script 
2018-05-30 11:48:35	jesse	now the biggest family im seeing is 166 
2018-05-30 14:52:21	msbrown3	merged it 
2018-05-30 14:53:00	jesse	ok. I've still been running the script. I'll send you the sql file when it finishes... may be a while though. 
2018-05-30 14:55:14	msbrown3	oh, sorry. I made it faster and pushed a few things 
2018-05-30 14:56:26	jesse	xD want me to rerun it? I made it so that it can't push duplicates which is nice, but it won't speed it up. 
2018-05-30 14:56:46	msbrown3	yeah, sure 
2018-05-30 14:57:09	msbrown3	`disease.get_family()` is pretty expensive so I made it only run once per disease, instead of one per link in each disease 
2018-05-30 14:57:39	jesse	oh wow. yeah thatll help haha 
2018-05-30 15:04:04	msbrown3	did you have any other changes after I merged your pull request? You just running the script now? 
2018-05-30 15:04:49	jesse	I don't think so. I'm just running it. I've been playing with other things like the multiple definitions and the pubmed stuff. 
2018-05-30 15:05:17	msbrown3	cool 
2018-05-30 15:06:10	jesse	well dang. the script is so much faster. cant believe i missed that one haha 
2018-05-30 15:07:06	msbrown3	haha, yeah. Easy to miss those things when you're worrying about actually making it work 
2018-05-30 15:20:35	jesse	I made a branch for displaying the multiple definitions on the about page. The only real change I made was that both of the definitions now appear. I wasn't able to get parts to hide (unless you want it to show one letter at a time haha). 
2018-05-30 15:24:00	msbrown3	ok cool! We can look at it tomorrow at the meeting. We might try to get collapsing before we merge 
2018-05-30 15:24:19	msbrown3	When your script is done, send it to Meaghan so she can push to production tonight 
2018-05-30 15:24:32	jesse	which script? 
2018-05-30 15:24:37	msbrown3	rareconnect 
2018-05-30 15:25:53	jesse	ahh. thats pushed on branch: issue86-rareconnect. I also have the sql file of the output if you want me to send it to you. It shouldn't have any duplicates cuz of how I made the models, but if you wanted to re-run it it only took about 10 minutes. 
2018-05-30 15:28:10	jesse	and the output is on power6a at ForTheGreatAndPowerfulMichael/support_group_rareconnect.sql 
2018-05-30 15:28:32	msbrown3	thanks! 
2018-05-31 10:32:30	jesse	Hey Michael, can I close the rareconnect communities issue? 
2018-05-31 10:33:15	msbrown3	Yes! Mention the commit or pull request or something in the closing message 
2018-05-31 10:46:52	jesse	I can show you around the pubmed repo if ya need. just give me a call or something. the only thing you really need to know is that there are 2 scripts in the scripts/ folder and there are 2 python programs in the pubmed/management/commands/ folder. The bash scripts need to be run first if you want to generate everything yourself (no need cuz I did it).  
2018-05-31 10:47:49	jesse	Also, I'm gonna ditch the multiple-definitions issue/branch. The only change I made was displaying both definitions, but I couldn't get the folding to work properly, so I'm leaving that to you guys :P 
2018-05-31 10:48:51	msbrown3	yeah, that would be nice. Do you want to do that soon? 
2018-05-31 10:49:26	msbrown3	good to know about the muiltple-definitions branch, we'll pick up that work next week probably 
2018-05-31 10:49:29	jesse	sure. I'm free all day. tel:704-787-4385 (704-787-4385) is my number. 
2018-05-31 13:27:23	jesse	I figured you would call me if you wanted to talk about pubmed stuff... just bein sure you arent waiting for me to call you xD 
2018-05-31 13:28:13	msbrown3	oh, yes. I was planning on it but I got distracted. Give me a few minutes (for real this time) 
2018-05-31 13:28:43	jesse	xD ok. 
2018-05-31 13:31:06	msbrown3	ok. about to call 
2018-05-31 13:31:21	jesse	cool 
2018-05-31 14:00:13	jesse	ftp://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/pubmed18n0940_stats.html 
2018-06-02 08:19:25	jesse	Michael, what is your profile picture? is there any significance with the red square? 
2018-06-04 09:11:00	msbrown3	It's a picture of an image processing technique for finding lines called a Hough Transform. 
2018-06-04 09:12:04	msbrown3	Basically a 2-d histogram of every possible line. The red squares are where it thinks it found a line 
2018-06-04 11:08:29	jesse	thats pretty cool. dunno what it would be used for though. maybe enhancing photos? 
2018-06-04 11:09:07	jesse	cuz you could use it to identify blurry parts of the photo maybe. 
2018-06-04 12:10:57	jesse	the pubmed baseline is done. elapsed time is 9 days and 9 hours. I think. could just be 9 days. 
2018-06-04 12:12:16	msbrown3	awesome! 
2018-06-20 13:10:44	jesse	Happy Birthday Michael!!! 
2018-06-20 13:45:54	msbrown3	Thanks! I mean, it's not my birthday until the 28th though =P 
2018-06-20 14:28:42	jesse	xD I wrote it in my calendar today 
2018-06-20 14:28:58	jesse	as today I mean. Ill update it. 
2018-06-20 14:30:00	jesse	But you have a Happy Birthday anyway!! celebrate it early xD 
2018-06-20 14:34:05	msbrown3	haha. I will =D 
2018-08-20 10:08:50		getting channel history...
2018-04-30 16:24:46	msbrown3	hmm.... that's weird 
2018-04-30 16:25:34	msbrown3	I wonder if the first one is getting duplicates for some reason.... I might not have that query right 
2018-04-30 16:26:40	msbrown3	I'd try a few things but atm I don't have enough ram on my machine..... I'm updating clinical trials 
2018-04-30 16:26:58	jesse	lol okay. I'm playing around with it rn 
2018-04-30 16:28:49	jesse	I've got a different script that works fine as a filter 
2018-04-30 16:29:07	jesse	In [16]: len(models.Phenotype.objects.exclude(diseasephenotype=None)) 
2018-04-30 16:29:07	jesse	Out[16]: 5456 
2018-04-30 16:29:39	msbrown3	cool 
2018-04-30 16:29:58	msbrown3	the one I gave you must have been selecting all disease-phenotype links or something 
2018-04-30 16:32:21	jesse	yeah it made me scratch my head lol 
2018-05-07 13:16:18	msbrown3	How long are you in town? 
2018-05-07 13:18:32	jesse	today and tomorrow up until my exam at 1 
2018-05-07 13:18:59	msbrown3	Do you have time to come in sometime before then? To talk about the PubMed database stuff? 
2018-05-07 13:21:24	jesse	Sure thing. I'm gonna be studying with some friends for a couple hours right now. But I can come in afterwards maybe around 4 if I'm being optimistic about my studying. 
2018-05-07 13:23:04	msbrown3	ok cool. That works for me. I can be around until about 6 
2018-05-07 13:25:44	msbrown3	I'm going to put some notes into the github issue. There will probably be a lot of questions/details that we can clarify in person 
2018-05-07 13:26:18	jesse	Okay. 
2018-05-07 16:12:13	jesse	I'm coming over now 
2018-05-07 16:12:48	msbrown3	great 
2018-05-09 12:53:46	msbrown3	btw, I forgot to mention where the setup docs for pubmed are: https://github.com/ITNG/pubmed/blob/master/docs/develop.md#one-time-setup
2018-05-09 12:53:46		ITNG/pubmed
2018-05-09 12:53:46		Contribute to pubmed development by creating an account on GitHub. 
2018-05-09 12:55:59	msbrown3	Pretty much what you're used to from rarediseases, but the settings stuff is a bit different. There's not a settings.py.ex, just an env file with the database url and such 
2018-05-09 14:40:22	jesse	sounds good. Ill be sure to keep it up to date if I change anything. 
2018-05-09 14:41:04	msbrown3	good, thanks! 
2018-05-10 21:02:18	jesse	This is one of the data sources we used for the health insurance data: https://www.healthcare.gov/health-plan-information-2018/
2018-05-10 21:02:18		Health Plan Information 2018 
2018-05-10 21:02:43	jesse	I'll try to find the other one. Our project wasn't very organized 
2018-05-10 21:04:22	jesse	https://www.cms.gov/CCIIO/Resources/Data-Resources/marketplace-puf.html 
2018-05-10 21:06:22	jesse	The data in there should be able to get the numerical data from the prices, deductibles, moops, and those other basic health insurance values. There is also a field within the first link that includes the "plan brochure", which I think is what you were referring to today in the meeting. 
2018-05-10 21:13:38	jesse	on google drive I also sent you my family's and my sister's health insurance plan... if you wanted to look at those.  I'll stop bombarding you with messages now. Good night dude. 
2018-05-14 07:28:10	msbrown3	Thanks. Sorry, I was busy moving on Friday so I was away from work 
2018-05-14 07:28:40	jesse	thats fine. i had a busy weekend too 
2018-05-14 09:33:33	jesse	Hey michael, do you know how I can switch my django db settings to use a postgres database? or would you rather me use sqlite? 
2018-05-14 09:42:27	jesse	I think I got it 
2018-05-14 10:11:47	msbrown3	ok 
2018-05-14 10:12:27	msbrown3	postgres is probably a good idea, but probably either would work for development 
2018-05-15 10:41:23	jesse	hey something you might wanna check out:  https://docs.djangoproject.com/en/dev/howto/custom-management-commands/  
2018-05-15 10:41:35	jesse	we can make our own manage.py commands.  
2018-05-15 10:43:03	msbrown3	yeah, I'm actually working on a new data script framework that adds a "data" command 
2018-05-15 10:43:36	msbrown3	It's pretty easy to use actually 
2018-05-15 10:44:36	jesse	cool! I figured out how to make one of my scripts work like that with the pubmed stuff. so much easier than copying and pasting into a python/django terminal 
2018-05-15 10:45:05	msbrown3	awesome! that will be really nice 
2018-05-17 09:37:43	jesse	hey Michael, does it make sense for my pubmed downloader to be in 'disk sleep' state most of the time? 
2018-05-17 09:38:18	jesse	I assume that means it's doing IO, which makes sense. 
2018-05-17 09:39:34	msbrown3	hmm, I don't know 
2018-05-17 09:40:19	msbrown3	ahh, yea I think that's fine.  "While waiting for read() or write() to/from a file descriptor return, the process will be put in a special kind of sleep, known as "D" or "Disk Sleep"" 
2018-05-17 09:40:19	jesse	usually when it's put in the D state it jumps out immediately after. I'll try running the program locally and see if it behaves similarly 
2018-05-17 09:40:27	msbrown3	https://stackoverflow.com/questions/1475683/linux-process-states
2018-05-17 09:40:27		Linux Process States
2018-05-17 09:40:27		In Linux, what happens to the state of a process when it needs to read blocks from a disk? Is it blocked? If so, how is another process chosen to execute? 
2018-05-17 09:43:07	jesse	ahh gotcha. 'Disk Sleep' made it sound like the hard drive was messed up haha. 
2018-05-17 09:43:14	msbrown3	yea, haha 
2018-05-17 09:58:52	jesse	should I call in again today for the meeting? 
2018-05-17 09:59:22	msbrown3	yeah. we're just moving into the conference room 
2018-05-17 09:59:37	msbrown3	we'll probably talk alot about the focus group that was on tuesday, and the upcoming one on Monday 
2018-05-21 08:28:12	jesse	Hey Michael, to let you know where I'm at, the baseline program is stable, and has been running for 9 hours now, but it's only managed to read 1 of the 927 files during that time. the progress bar estimates that it will complete in 149 days. I'm thinking about ways to speed it up but we may lose the connection between authors and articles,  as well as articles and mesh headings. 
2018-05-21 08:29:43	jesse	I'm thinking about making a giant list of article objects and then bulk saving them into the database, cuz I think most of the time is being lost through context switches. 
2018-05-21 09:46:06	msbrown3	yeah, the bulk save is a good idea. In my experience the number of database calls is what makes these data scripts so slow 
2018-05-21 09:48:22	jesse	the only issue with that is that using many to many fields require both objects to be in the database first. 
2018-05-21 09:48:59	jesse	so I'm probably just gonna try storing the ids. 
2018-05-21 09:49:31	msbrown3	Is the authors table small enough you can store that in memory until the end? 
2018-05-21 09:52:45	jesse	I doubt it. but im not sure. 
2018-05-21 10:48:01	jesse	new time estimate is about 5 days. I'm not sure what to do about how to relate the pubmed articles to the authors or the headings. right now, the authors and the headings just have a pmid field that points it to the article but not the other way around because I wouldn't know what the id field of the authors or the headings is, since they are auto-generated. 
2018-05-21 10:48:56	jesse	authors and mesh headings will also contain a lot of duplicated info, since I'm doing bulk inserts rather than a update_or_create kind of thing. 
2018-05-21 10:51:18	msbrown3	ok. that sounds fine for now. I don't imagine having duplicate authors will take up that much space compared to the pubmed articles themselves 
2018-05-21 10:52:16	jesse	alright. I agree. I'll try to do something about the daily updates for the time being. 
2018-05-21 10:52:29	msbrown3	ok cool 
2018-05-21 10:52:41	msbrown3	thanks for the update 
2018-05-21 11:44:15	jesse	I wrote the script for the daily updates but I will need all the pubmed articles in to test it. Everythings pushed if you wanted to take a look and see if you can spot bugs, but aside from that and waiting for the main script to finish, I should be free to work on something else. 
2018-05-21 11:44:56	jesse	Also, I don't think those update files include removing articles, so I didn't account for it. 
2018-05-21 13:40:29	msbrown3	do they have any mechanism for removing articles? 
2018-05-21 13:41:21	jesse	it didnt look like it. I could have missed it though. it looked like the same format as the baseline stuff. 
2018-05-21 13:43:19	msbrown3	hmm, okay 
2018-05-21 13:48:32	jesse	ill double check later to be sure 
2018-05-29 09:55:56	msbrown3	Hey Jesse. I noticed the rareconnect communities runs really slow. Do you think you have time to make it faster by tomorrow night for the production push? 
2018-05-29 10:07:34	jesse	ahh really? i thought it was running fine when I checked. I'll do something about it 
2018-05-29 10:11:56	msbrown3	cool, thanks 
2018-05-29 10:26:10	jesse	i was running it on my desktop :P 
2018-05-29 10:26:10		maybe thats why it was quick for me. 
2018-05-29 10:28:12	msbrown3	hmm yeah. I wounder if production is faster than my VM 
2018-05-29 14:12:02	jesse	hey michael, does disease.get_family include the disease itself? 
2018-05-29 14:12:37	jesse	I think it does based on the code in disease.py but i wanted to double check. 
2018-05-29 14:13:41	jesse	nvm it does. 
2018-05-29 14:14:00	msbrown3	yeah 
2018-05-29 14:16:27	jesse	one more thing: how do you typically run django scripts? 
2018-05-29 14:17:10	jesse	putting it in management/commands works well for me, but before that, I was just copying and pasting code into the django shell... and that didnt work well. 
2018-05-29 14:18:06	jesse	all of our scripts being in a scripts directory makes that a bit difficult unless I copy the scripts I need over into management/commands. 
2018-05-29 14:19:39	msbrown3	`python scripts/foo.py` 
2018-05-29 14:20:33	msbrown3	I've been working on a script framework for rarediseases, so it's moving to useage like this: `./manage.py data run OrphaDisease` 
2018-05-29 14:20:33	jesse	does that work if you are messing with Disease.objects.blah? 
2018-05-29 14:23:13	msbrown3	yes if you put some stuff at the beginning that initializes django 
2018-05-29 14:23:38	jesse	ahh. That must be what I've been missing. 
2018-05-29 14:24:24	msbrown3	```python
2018-05-29 14:24:24		import django
2018-05-29 14:24:24		os.environ.setdefault("DJANGO_SETTINGS_MODULE", "project.settings")
2018-05-29 14:24:24		django.setup()
2018-05-29 14:24:24		``` 
2018-05-29 14:25:35	msbrown3	uhh, can't edit that for some reason, but "python" shouldn't be in the first line 
2018-05-29 14:26:03	jesse	i gotcha.  
2018-05-29 14:57:03	jesse	I just screwed up django...  
2018-05-29 14:57:11	jesse	xD nothing is working now 
2018-05-29 15:11:26	msbrown3	O.o 
2018-05-29 15:11:29	msbrown3	what's happening? 
2018-05-29 15:12:06	jesse	nothing. any process going through manage.py just hangs. 
2018-05-29 15:12:35	jesse	i'm going through the setup process again now 
2018-05-29 15:12:48	msbrown3	for pubmed or rarediseases? 
2018-05-29 15:14:35	msbrown3	you could try using the debugger: `pip install ipdb; python -m ipdb manage.py` 
2018-05-29 15:14:41	msbrown3	to see where it's hanging 
2018-05-29 15:15:14	jesse	rarediseases. and thanks. I'll give that a try. 
2018-05-29 15:24:50	jesse	it somehow was related to pycache... removing it fixed the issue 
2018-05-29 15:29:22	msbrown3	weird 
2018-05-29 17:26:55	jesse	do you know why django isn't creating the tables when I add something into models/ makemigrations/ migrate? 
2018-05-30 08:19:40	msbrown3	are you using `--database data` when mirgating? 
2018-05-30 08:20:43	jesse	i think I tried it, but it didnt do anything. 
2018-05-30 08:23:42	msbrown3	hmm. does the migration file actually have a create table operation in it? 
2018-05-30 08:36:57	jesse	I'll check in a moment. I'm not at my computer rn 
2018-05-30 08:53:01	jesse	it does not. it has create model operations in it though. I kinda think it's because I'm using old data. 
2018-05-30 08:55:02	jesse	wait... --database data may have fixed it... I thought I tried that.  
2018-05-30 08:55:30	msbrown3	oh cool 
2018-05-30 08:55:46	msbrown3	the create model operation should create the table in the database 
2018-05-30 09:02:47	jesse	actually i was wrong... I forgot I tried making a table in the db last night.. my program had an issue with the auto id field which is why i wanted django to make the table for me. 
2018-05-30 09:10:01	jesse	ok. so I got the tables to generate for every other table other than the one I created. am I supposed to do something other than add the Model to the models folder? 
2018-05-30 09:10:42	msbrown3	oh, you should import it in rarediseases/models/__init__.py 
2018-05-30 09:11:21	jesse	yeah i did that :( 
2018-05-30 09:11:34	msbrown3	:disappointed: 
2018-05-30 09:16:49	jesse	got it! i made it generate in a separate db and I pg_dumped it into mine :P 
2018-05-30 09:19:41	jesse	One more thing:  the program runs very slowly making all of the comparisons. I'm thinking some of the diseases families might be very big which means I'm doing a lot more comparisons than i need. Do you think I should limit it to only compare 5 branches in it's family path? 
2018-05-30 10:04:12	msbrown3	how slowly does it run? Can you speed it up by making an index dictionary for the community names or something? 
2018-05-30 10:06:58	jesse	it took about 10 minutes to go through the disease at index 6. which means it would take 10 minutes for any disease within object 6ths family graph. and there is 10,000 objects 
2018-05-30 10:07:07	jesse	total. 
2018-05-30 10:08:41	jesse	but I am going through each disease and comparing every rareconnect link with  each of them. 
2018-05-30 10:10:42	jesse	also, it seems like steel syndrome is showing results for eec syndrome, ehlers danlos syndrome, nephrotic syndrome and some others that im not sure are related 
2018-05-30 10:14:23	msbrown3	hmm... is the disease family thing not doing what you want? 
2018-05-30 10:14:39	msbrown3	also, the disease family query is kindof expensive in itself 
2018-05-30 10:19:15	jesse	it is very expensive. the script runs 10 seconds without checking the family, but going one family member deep makes the scripts ETA hours... It seems to be doing what I want, but I think I'm misunderstanding how big these trees are. it might give us misleading results if we check all of them.  
2018-05-30 10:20:10	msbrown3	I think some of the families are big, but shouldn't be that many of them 
2018-05-30 10:20:20	msbrown3	that is, most should be small 
2018-05-30 10:21:59	jesse	I'll spend some more time trying to make it more efficient and see where it takes me.  
2018-05-30 10:22:48	msbrown3	ok 
2018-05-30 11:36:55	jesse	I found a way to make it a bit more efficient, but the biggest issue that is taking the processing time is checking every family member. There were 2 diseases that I saw with family members over 900 family members... which means that there are 900 diseases each with at least 900 family members making for 810,000 comparisons. and I found 2 of those.  I'll try to run it without limitting the families and get an estimate for how long the script will run.  
2018-05-30 11:37:46	jesse	right now, it might be 8-24 hours. 
2018-05-30 11:38:18	msbrown3	wow, why are there 900? 
2018-05-30 11:40:21	msbrown3	can you give me an example disease? 
2018-05-30 11:40:24	jesse	i dunno. the id was 39084. id_orpha=183763 if you wanna check it out. 
2018-05-30 11:40:33	msbrown3	yeah 
2018-05-30 11:41:25	jesse	Rare genetic syndromic intellectual disability is the name... which seems very vague 
2018-05-30 11:41:36	msbrown3	yeah... it's a category 
2018-05-30 11:42:06	msbrown3	ohhhh, and it has 387 children, each of which probably have a few subtypes 
2018-05-30 11:42:36	jesse	I filtered the diseases to not include categories, but that kind of code isn't included in the get_family() function 
2018-05-30 11:44:33	jesse	as in get_family will return categories or parents/children of categories. 
2018-05-30 11:44:34	msbrown3	all of a disease's family should have is_category=False, it filters for that 
2018-05-30 11:44:55	jesse	okay. thats good. 
2018-05-30 11:45:50	msbrown3	but you're calling get_family() on a category? 
2018-05-30 11:47:43	jesse	nah I removed that problem :) 
2018-05-30 11:47:58	jesse	in my test program i was though 
2018-05-30 11:48:05	jesse	not my script 
2018-05-30 11:48:35	jesse	now the biggest family im seeing is 166 
2018-05-30 14:52:21	msbrown3	merged it 
2018-05-30 14:53:00	jesse	ok. I've still been running the script. I'll send you the sql file when it finishes... may be a while though. 
2018-05-30 14:55:14	msbrown3	oh, sorry. I made it faster and pushed a few things 
2018-05-30 14:56:26	jesse	xD want me to rerun it? I made it so that it can't push duplicates which is nice, but it won't speed it up. 
2018-05-30 14:56:46	msbrown3	yeah, sure 
2018-05-30 14:57:09	msbrown3	`disease.get_family()` is pretty expensive so I made it only run once per disease, instead of one per link in each disease 
2018-05-30 14:57:39	jesse	oh wow. yeah thatll help haha 
2018-05-30 15:04:04	msbrown3	did you have any other changes after I merged your pull request? You just running the script now? 
2018-05-30 15:04:49	jesse	I don't think so. I'm just running it. I've been playing with other things like the multiple definitions and the pubmed stuff. 
2018-05-30 15:05:17	msbrown3	cool 
2018-05-30 15:06:10	jesse	well dang. the script is so much faster. cant believe i missed that one haha 
2018-05-30 15:07:06	msbrown3	haha, yeah. Easy to miss those things when you're worrying about actually making it work 
2018-05-30 15:20:35	jesse	I made a branch for displaying the multiple definitions on the about page. The only real change I made was that both of the definitions now appear. I wasn't able to get parts to hide (unless you want it to show one letter at a time haha). 
2018-05-30 15:24:00	msbrown3	ok cool! We can look at it tomorrow at the meeting. We might try to get collapsing before we merge 
2018-05-30 15:24:19	msbrown3	When your script is done, send it to Meaghan so she can push to production tonight 
2018-05-30 15:24:32	jesse	which script? 
2018-05-30 15:24:37	msbrown3	rareconnect 
2018-05-30 15:25:53	jesse	ahh. thats pushed on branch: issue86-rareconnect. I also have the sql file of the output if you want me to send it to you. It shouldn't have any duplicates cuz of how I made the models, but if you wanted to re-run it it only took about 10 minutes. 
2018-05-30 15:28:10	jesse	and the output is on power6a at ForTheGreatAndPowerfulMichael/support_group_rareconnect.sql 
2018-05-30 15:28:32	msbrown3	thanks! 
2018-05-31 10:32:30	jesse	Hey Michael, can I close the rareconnect communities issue? 
2018-05-31 10:33:15	msbrown3	Yes! Mention the commit or pull request or something in the closing message 
2018-05-31 10:46:52	jesse	I can show you around the pubmed repo if ya need. just give me a call or something. the only thing you really need to know is that there are 2 scripts in the scripts/ folder and there are 2 python programs in the pubmed/management/commands/ folder. The bash scripts need to be run first if you want to generate everything yourself (no need cuz I did it).  
2018-05-31 10:47:49	jesse	Also, I'm gonna ditch the multiple-definitions issue/branch. The only change I made was displaying both definitions, but I couldn't get the folding to work properly, so I'm leaving that to you guys :P 
2018-05-31 10:48:51	msbrown3	yeah, that would be nice. Do you want to do that soon? 
2018-05-31 10:49:26	msbrown3	good to know about the muiltple-definitions branch, we'll pick up that work next week probably 
2018-05-31 10:49:29	jesse	sure. I'm free all day. tel:704-787-4385 (704-787-4385) is my number. 
2018-05-31 13:27:23	jesse	I figured you would call me if you wanted to talk about pubmed stuff... just bein sure you arent waiting for me to call you xD 
2018-05-31 13:28:13	msbrown3	oh, yes. I was planning on it but I got distracted. Give me a few minutes (for real this time) 
2018-05-31 13:28:43	jesse	xD ok. 
2018-05-31 13:31:06	msbrown3	ok. about to call 
2018-05-31 13:31:21	jesse	cool 
2018-05-31 14:00:13	jesse	ftp://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/pubmed18n0940_stats.html 
2018-06-02 08:19:25	jesse	Michael, what is your profile picture? is there any significance with the red square? 
2018-06-04 09:11:00	msbrown3	It's a picture of an image processing technique for finding lines called a Hough Transform. 
2018-06-04 09:12:04	msbrown3	Basically a 2-d histogram of every possible line. The red squares are where it thinks it found a line 
2018-06-04 11:08:29	jesse	thats pretty cool. dunno what it would be used for though. maybe enhancing photos? 
2018-06-04 11:09:07	jesse	cuz you could use it to identify blurry parts of the photo maybe. 
2018-06-04 12:10:57	jesse	the pubmed baseline is done. elapsed time is 9 days and 9 hours. I think. could just be 9 days. 
2018-06-04 12:12:16	msbrown3	awesome! 
2018-06-20 13:10:44	jesse	Happy Birthday Michael!!! 
2018-06-20 13:45:54	msbrown3	Thanks! I mean, it's not my birthday until the 28th though =P 
2018-06-20 14:28:42	jesse	xD I wrote it in my calendar today 
2018-06-20 14:28:58	jesse	as today I mean. Ill update it. 
2018-06-20 14:30:00	jesse	But you have a Happy Birthday anyway!! celebrate it early xD 
2018-06-20 14:34:05	msbrown3	haha. I will =D 
2018-08-19 21:14:01	jesse	Hey Michael, are you guys gonna be in the lab tomorrow? 
2018-08-19 21:15:00	jesse	i was gonna stop by and see if there are things you all would like me started on (if John and Mike still want me around) 
2018-08-19 21:50:31	msbrown3	Yeah. We'll be at the lab 
2018-08-19 21:52:26	msbrown3	You're welcome to come tomorrow. We're definitely planning on having you back. No idea what the paperwork situation is, so that's something to ask John about. 
2018-08-19 21:53:06	jesse	okay. Thanks!! 
2018-08-20 10:16:15	msbrown3	```
2018-08-20 10:16:15		SELECT
2018-08-20 10:16:15		    table_name,
2018-08-20 10:16:15		    pg_size_pretty(table_size) AS table_size,
2018-08-20 10:16:15		    pg_size_pretty(indexes_size) AS indexes_size,
2018-08-20 10:16:15		    pg_size_pretty(total_size) AS total_size
2018-08-20 10:16:15		FROM (
2018-08-20 10:16:15		    SELECT
2018-08-20 10:16:15		        table_name,
2018-08-20 10:16:15		        pg_table_size(table_name) AS table_size,
2018-08-20 10:16:15		        pg_indexes_size(table_name) AS indexes_size,
2018-08-20 10:16:15		        pg_total_relation_size(table_name) AS total_size
2018-08-20 10:16:15		    FROM (
2018-08-20 10:16:15		        SELECT ('"' || table_schema || '"."' || table_name || '"') AS table_name
2018-08-20 10:16:15		        FROM information_schema.tables
2018-08-20 10:16:15		    ) AS all_tables
2018-08-20 10:16:15		    ORDER BY total_size DESC
2018-08-20 10:16:15		) AS pretty_sizes;
2018-08-20 10:16:15		``` 
